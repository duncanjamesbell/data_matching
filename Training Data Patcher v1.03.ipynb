{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc, math, numbers, operator, os, re, time\n",
    "from collections import defaultdict, Counter\n",
    "from statistics import stdev\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from jellyfish import jaro_winkler, metaphone\n",
    "from py_common_subseq import find_common_subsequences\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: ParserWarning: Both a converter and dtype were specified for column zip_l - only the converter will be used\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: ParserWarning: Both a converter and dtype were specified for column zip_r - only the converter will be used\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: ParserWarning: Both a converter and dtype were specified for column zip_l - only the converter will be used\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: ParserWarning: Both a converter and dtype were specified for column zip_r - only the converter will be used\n"
     ]
    }
   ],
   "source": [
    "#load new training records here\n",
    "\n",
    "new_training_filepath = 'data/Training Data Patcher/NCMA training examples.csv'\n",
    "file_utf = new_training_filepath[:-(len(new_training_filepath)-(new_training_filepath.find('.',len(new_training_filepath)-6)))] + '_utf' + new_training_filepath[-(len(new_training_filepath)-(new_training_filepath.find('.',len(new_training_filepath)-6))):]\n",
    "file_utf\n",
    "\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "with io.open(new_training_filepath, encoding='utf-8', errors='ignore') as source:\n",
    "    with io.open(file_utf, mode='w', encoding='utf-8') as target:\n",
    "        shutil.copyfileobj(source,target)\n",
    "        \n",
    "new_training = pd.read_csv(file_utf,dtype=object,converters={'zip_l': lambda x: str(x),'zip_r': lambda x: str(x)}\n",
    "                         #,nrows=1000\n",
    "                         )\n",
    "'''\n",
    "#could use this code in case we need to add a feature to training data, but it's not needed otherwise given intersection()\n",
    "org_training_cols = ['id','id_l','id_r','id_l count', 'is_match']\n",
    "#in case we add any other features to training data, add them to below list\n",
    "for col in ['org_name','city','state','zip','web','phone','email']\n",
    "    org_training_cols.append:\n",
    "        col + '_l'\n",
    "        col + '_r'\n",
    "\n",
    "person_training_cols = ['id','id_l','id_r','org_person_id_l','org_person_id_r', 'is_match']\n",
    "#in case we add any other features to training data, add them to below list\n",
    "for col in ['prefix','fname','mname','lname','suffix','gender','org_name','position','city','state','zip','email','phone','web']:\n",
    "    person_training_cols.append:\n",
    "        col + '_l'\n",
    "        col + '_r'\n",
    "'''\n",
    "\n",
    "#determine if incoming data is for organization matching or person matching\n",
    "if 'fname_l' in new_training:\n",
    "    organization_only = False\n",
    "else:\n",
    "    organization_only = True\n",
    "        \n",
    "if organization_only:\n",
    "    current_training_records = pd.read_csv('org_training_featureless.csv',dtype=object,converters={'zip_l': lambda x: str(x),'zip_r': lambda x: str(x)})\n",
    "    #combine current training records with new training records    \n",
    "    featureless = pd.concat([current_training_records,new_training[intersection(list(current_training_records.columns),list(new_training.columns))]],sort=False)\n",
    "    featureless.drop_duplicates(inplace=True) #make sure we haven't added multiple rows for the same two records\n",
    "    featureless.to_csv('org_training_featureless.csv',index=False) #save a new set of featureless for the next time\n",
    "else:\n",
    "    with io.open('person_training_featureless.csv', encoding='utf-8', errors='ignore') as source:\n",
    "        with io.open('person_training_featureless_utf.csv', mode='w', encoding='utf-8') as target:\n",
    "            shutil.copyfileobj(source,target)\n",
    "    current_training_records = pd.read_csv('person_training_featureless_utf.csv',dtype=object,converters={'zip_l': lambda x: str(x),'zip_r': lambda x: str(x)})\n",
    "    #combine current training records with new training records    \n",
    "    featureless = pd.concat([current_training_records,new_training[intersection(list(current_training_records.columns),list(new_training.columns))]],sort=False)\n",
    "    featureless.drop_duplicates(inplace=True) #make sure we haven't added multiple rows for the same two records\n",
    "    featureless.to_csv('person_training_featureless.csv',index=False) #save a new set of featureless for the next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to load featureless data and not add any new records, used for tweaking the features\n",
    "try:\n",
    "    new_training\n",
    "    new=True\n",
    "except:\n",
    "    import io\n",
    "    import shutil\n",
    "    #I think this file needs to be updated to reference the current person_training_featureless\n",
    "    with io.open('person_training_featureless_reduced.csv', encoding='utf-8', errors='ignore') as source:\n",
    "        with io.open('person_training_featureless_utf.csv', mode='w', encoding='utf-8') as target:\n",
    "            shutil.copyfileobj(source,target)\n",
    "    featureless = pd.read_csv('person_training_featureless_utf.csv',dtype=object,converters={'zip_l': lambda x: str(x),'zip_r': lambda x: str(x)})\n",
    "    new=False\n",
    "    organization_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if new:\n",
    "    intersection(list(new_training.columns),list(current_training_records.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_l</th>\n",
       "      <th>org_person_id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>org_person_id_r</th>\n",
       "      <th>is_match</th>\n",
       "      <th>prefix_l</th>\n",
       "      <th>fname_l</th>\n",
       "      <th>mname_l</th>\n",
       "      <th>lname_l</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_r</th>\n",
       "      <th>org_name_r</th>\n",
       "      <th>position_r</th>\n",
       "      <th>city_r</th>\n",
       "      <th>state_r</th>\n",
       "      <th>zip_r</th>\n",
       "      <th>email_r</th>\n",
       "      <th>phone_r</th>\n",
       "      <th>web_l</th>\n",
       "      <th>web_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>874427</td>\n",
       "      <td>106963</td>\n",
       "      <td>96887</td>\n",
       "      <td>216622</td>\n",
       "      <td>209040</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nathalie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leplat</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>ca applicants' attorney association</td>\n",
       "      <td>Administrative Assistant, Hotel Contact and CA...</td>\n",
       "      <td>sacramento</td>\n",
       "      <td>ca</td>\n",
       "      <td>95814</td>\n",
       "      <td>nathalie@caaa.org</td>\n",
       "      <td>9164445155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1404715</td>\n",
       "      <td>206379</td>\n",
       "      <td>198238</td>\n",
       "      <td>254014</td>\n",
       "      <td>520751</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karianne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fallow</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>dairy west</td>\n",
       "      <td>Chief Executive Officer</td>\n",
       "      <td>meridian</td>\n",
       "      <td>id</td>\n",
       "      <td>83642</td>\n",
       "      <td>kfallow@dairywest.com</td>\n",
       "      <td>2083277050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94393</td>\n",
       "      <td>277502</td>\n",
       "      <td>358545</td>\n",
       "      <td>328968</td>\n",
       "      <td>322757</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latessa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>american farm bureau federation</td>\n",
       "      <td>Director, Show</td>\n",
       "      <td>washington</td>\n",
       "      <td>dc</td>\n",
       "      <td>20024</td>\n",
       "      <td>amy.latessa@ideaggroup.com</td>\n",
       "      <td>8156213254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419406</td>\n",
       "      <td>288744</td>\n",
       "      <td>281663</td>\n",
       "      <td>288745</td>\n",
       "      <td>281664</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james m.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gates</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ny on shrine association</td>\n",
       "      <td>Treasurer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>jmgates46@twcny.rr.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409311</td>\n",
       "      <td>278524</td>\n",
       "      <td>306589</td>\n",
       "      <td>357430</td>\n",
       "      <td>271213</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>evan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lynch</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>international clarinet association</td>\n",
       "      <td>Interim Executive Director</td>\n",
       "      <td>columbus</td>\n",
       "      <td>oh</td>\n",
       "      <td>43214</td>\n",
       "      <td>evanlynchica@gmail.com</td>\n",
       "      <td>8889835441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    id_l org_person_id_l    id_r org_person_id_r is_match prefix_l  \\\n",
       "0   874427  106963           96887  216622          209040        1      NaN   \n",
       "1  1404715  206379          198238  254014          520751        1      NaN   \n",
       "2    94393  277502          358545  328968          322757        1      NaN   \n",
       "3  1419406  288744          281663  288745          281664        1      NaN   \n",
       "4   409311  278524          306589  357430          271213        1      NaN   \n",
       "\n",
       "     fname_l mname_l  lname_l  ... gender_r  \\\n",
       "0   nathalie     NaN   leplat  ...        F   \n",
       "1  karianne      NaN   fallow  ...        F   \n",
       "2       amy      NaN  latessa  ...      NaN   \n",
       "3   james m.     NaN    gates  ...      NaN   \n",
       "4      evan      NaN    lynch  ...        M   \n",
       "\n",
       "                            org_name_r  \\\n",
       "0  ca applicants' attorney association   \n",
       "1                           dairy west   \n",
       "2      american farm bureau federation   \n",
       "3             ny on shrine association   \n",
       "4   international clarinet association   \n",
       "\n",
       "                                          position_r      city_r state_r  \\\n",
       "0  Administrative Assistant, Hotel Contact and CA...  sacramento      ca   \n",
       "1                            Chief Executive Officer    meridian      id   \n",
       "2                                     Director, Show  washington      dc   \n",
       "3                                          Treasurer         NaN     NaN   \n",
       "4                         Interim Executive Director    columbus      oh   \n",
       "\n",
       "   zip_r                     email_r     phone_r web_l web_r  \n",
       "0  95814           nathalie@caaa.org  9164445155   NaN   NaN  \n",
       "1  83642       kfallow@dairywest.com  2083277050   NaN   NaN  \n",
       "2  20024  amy.latessa@ideaggroup.com  8156213254   NaN   NaN  \n",
       "3             jmgates46@twcny.rr.com         NaN   NaN   NaN  \n",
       "4  43214      evanlynchica@gmail.com  8889835441   NaN   NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureless.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99871, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureless.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing items that need to happen before we can do scoring\n",
    "\n",
    "featureless = featureless.dropna(how='all')                    # Drop all empty rows\n",
    "featureless = featureless.fillna('')                           # Make any NA an empty string\n",
    "featureless = featureless.applymap(str.lower)                  # Lowercase all fields\n",
    "featureless = featureless.applymap(str.strip)                  # Strip whitespace from all fields\n",
    "\n",
    "\"\"\"\n",
    "Prepare the places lookup table\n",
    "\n",
    "\"\"\"\n",
    "# Get and lowercase the state codes data\n",
    "df_states = pd.read_csv('data/state_lkup.csv', keep_default_na=False)\n",
    "df_states = df_states.applymap(str.lower)\n",
    "df_states = df_states.set_index(\"state\")\n",
    "\n",
    "# Get and lowercase the country codes data\n",
    "df_countries = pd.read_csv('data/country codes.csv', keep_default_na=False)\n",
    "df_countries = df_countries.applymap(str.lower)\n",
    "df_countries = df_countries.set_index(\"COUNTRY\")\n",
    "\n",
    "place_acronyms = defaultdict(str,\n",
    "                             {**df_states[\"acronym\"].to_dict(),\n",
    "                              **df_countries[\"ISO2\"].to_dict()})\n",
    "\n",
    "for col in ['state_l','state_r', 'org_name_l','org_name_r']:\n",
    "    featureless[col] = featureless[col].replace(regex=place_acronyms)\n",
    "    \n",
    "## Patch in nicknames\n",
    "if 'fname_l' in featureless:\n",
    "    # Load in nicknames\n",
    "    df_nicks = pd.read_csv('data/nicknames.csv', sep='\\n', header=None, names=[\"names\"])\n",
    "    df_nicks[\"names\"] = df_nicks[\"names\"].str.lower().str.split(',')\n",
    "    nicks = defaultdict(set)  # A dictionary with a default value of an empty set\n",
    "    df_nicks.apply(lambda row: list(map(lambda name: nicks[name].add(row.name), row[\"names\"])),\n",
    "                   axis = \"columns\")\n",
    "    \n",
    "    featureless['nicks_groups_l'] = featureless[\"fname_l\"].apply(lambda n: \" \".join(map(lambda grp: \"nick\" + str(grp), nicks[n])))\n",
    "    featureless['nicks_groups_r'] = featureless[\"fname_r\"].apply(lambda n: \" \".join(map(lambda grp: \"nick\" + str(grp), nicks[n])))\n",
    "\n",
    "    #adding full name cols\n",
    "    featureless['full_name_l'] = featureless['fname_l'] + ' ' + featureless['lname_l']\n",
    "    featureless['full_name_r'] = featureless['fname_r'] + ' ' + featureless['lname_r']\n",
    "\n",
    "#adding clean phone cols\n",
    "if 'clean_phone_l' not in featureless:\n",
    "    featureless['clean_phone_l'] = featureless['phone_l'].replace('[^0-9]', '',regex=True)\n",
    "    featureless['clean_phone_r'] = featureless['phone_r'].replace('[^0-9]', '',regex=True)\n",
    "\n",
    "#adding before email & domain cols\n",
    "personal_domains = pd.read_csv('data/personal email domains.csv')['domain']\n",
    "\n",
    "if 'email_l' in featureless:\n",
    "    featureless[['before_domain_l', 'domain_l']] = featureless['email_l'].str.split('@', expand=True)[[0, 1]]\n",
    "    featureless['domain_l'] = featureless['domain_l'].map(lambda d: '' if d in personal_domains else d)\n",
    "    \n",
    "    featureless[['before_domain_r', 'domain_r']] = featureless['email_r'].str.split('@', expand=True)[[0, 1]]\n",
    "    featureless['domain_r'] = featureless['domain_r'].map(lambda d: '' if d in personal_domains else d)\n",
    "\n",
    "if 'web_l' in featureless and organization_only == True:\n",
    "    for col in ['web_l','web_r']:   \n",
    "        domains = []\n",
    "        for web in featureless[col]:\n",
    "            if '@' in web: #handle domain extraction in case we want to use an email address\n",
    "                domain = web.split('@')[-1]\n",
    "                if domain in list(personal_domains): \n",
    "                    domains.append('')\n",
    "                else:\n",
    "                    domains.append(domain)\n",
    "            elif '/' in web or 'www' in web: #assuming we have a URL\n",
    "                domains.append(web.split('//')[-1].split('/')[0].strip('www.'))\n",
    "            elif '.' in web: #handling cases where URL is already a domain\n",
    "                domains.append(web)\n",
    "            else:\n",
    "                domains.append('')\n",
    "        col_name = 'domain_' + col[-1]\n",
    "        if col_name in list(featureless.columns): #handle if we already have domain column from emails\n",
    "            complete_domains = []\n",
    "            domain_df = pd.DataFrame(domains,columns=['website_domain'])\n",
    "            domain_df['email_domain'] = featureless[col_name]\n",
    "            for index, row in domain_df.iterrows():\n",
    "                if len(row['website_domain']) > 0:\n",
    "                    complete_domains.append(row['website_domain']) #prefer website domain\n",
    "                else:\n",
    "                    complete_domains.append(row['email_domain'])\n",
    "            featureless[col_name] = complete_domains\n",
    "        else: #in case there is no email column, then we take all domains from website\n",
    "            featureless[col_name] = domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tjaro scores done --- 11.462361097335815 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_l</th>\n",
       "      <th>org_person_id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>org_person_id_r</th>\n",
       "      <th>is_match</th>\n",
       "      <th>prefix_l</th>\n",
       "      <th>fname_l</th>\n",
       "      <th>mname_l</th>\n",
       "      <th>lname_l</th>\n",
       "      <th>...</th>\n",
       "      <th>nicks_groups_r</th>\n",
       "      <th>full_name_l</th>\n",
       "      <th>full_name_r</th>\n",
       "      <th>clean_phone_l</th>\n",
       "      <th>clean_phone_r</th>\n",
       "      <th>before_domain_l</th>\n",
       "      <th>domain_l</th>\n",
       "      <th>before_domain_r</th>\n",
       "      <th>domain_r</th>\n",
       "      <th>jaro_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>874427</td>\n",
       "      <td>106963</td>\n",
       "      <td>96887</td>\n",
       "      <td>216622</td>\n",
       "      <td>209040</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>nathalie</td>\n",
       "      <td></td>\n",
       "      <td>leplat</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>nathalie leplat</td>\n",
       "      <td>nathalie leplat</td>\n",
       "      <td></td>\n",
       "      <td>9164445155</td>\n",
       "      <td>nathalie</td>\n",
       "      <td>caaa.org</td>\n",
       "      <td>nathalie</td>\n",
       "      <td>caaa.org</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1404715</td>\n",
       "      <td>206379</td>\n",
       "      <td>198238</td>\n",
       "      <td>254014</td>\n",
       "      <td>520751</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>karianne</td>\n",
       "      <td></td>\n",
       "      <td>fallow</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>karianne fallow</td>\n",
       "      <td>karianne fallow</td>\n",
       "      <td></td>\n",
       "      <td>2083277050</td>\n",
       "      <td>kfallow</td>\n",
       "      <td>udidaho.org</td>\n",
       "      <td>kfallow</td>\n",
       "      <td>dairywest.com</td>\n",
       "      <td>0.560317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94393</td>\n",
       "      <td>277502</td>\n",
       "      <td>358545</td>\n",
       "      <td>328968</td>\n",
       "      <td>322757</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>amy</td>\n",
       "      <td></td>\n",
       "      <td>latessa</td>\n",
       "      <td>...</td>\n",
       "      <td>nick64</td>\n",
       "      <td>amy latessa</td>\n",
       "      <td>amy latessa</td>\n",
       "      <td></td>\n",
       "      <td>8156213254</td>\n",
       "      <td>amy.latessa</td>\n",
       "      <td>ideaggroup.com</td>\n",
       "      <td>amy.latessa</td>\n",
       "      <td>ideaggroup.com</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419406</td>\n",
       "      <td>288744</td>\n",
       "      <td>281663</td>\n",
       "      <td>288745</td>\n",
       "      <td>281664</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>james m.</td>\n",
       "      <td></td>\n",
       "      <td>gates</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>james m. gates</td>\n",
       "      <td>james m. gates</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>jmgates46</td>\n",
       "      <td>twcny.rr.com</td>\n",
       "      <td>jmgates46</td>\n",
       "      <td>twcny.rr.com</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409311</td>\n",
       "      <td>278524</td>\n",
       "      <td>306589</td>\n",
       "      <td>357430</td>\n",
       "      <td>271213</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>evan</td>\n",
       "      <td></td>\n",
       "      <td>lynch</td>\n",
       "      <td>...</td>\n",
       "      <td>nick390</td>\n",
       "      <td>evan lynch</td>\n",
       "      <td>evan lynch</td>\n",
       "      <td></td>\n",
       "      <td>8889835441</td>\n",
       "      <td>evanlynchica</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>evanlynchica</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99866</th>\n",
       "      <td></td>\n",
       "      <td>e17bca27-82c2-4510-907a-847dcd1f968b</td>\n",
       "      <td></td>\n",
       "      <td>1484c243-1d4e-43d1-bf6a-5aeb6d039677</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>george</td>\n",
       "      <td>r.</td>\n",
       "      <td>powers</td>\n",
       "      <td>...</td>\n",
       "      <td>nick430 nick431</td>\n",
       "      <td>george powers</td>\n",
       "      <td>george powell</td>\n",
       "      <td>7032988425</td>\n",
       "      <td>4152815412</td>\n",
       "      <td>george.r.powers</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>george.powell</td>\n",
       "      <td>stantec.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99867</th>\n",
       "      <td></td>\n",
       "      <td>5077450f-d025-471c-ac08-fef9165e638a</td>\n",
       "      <td></td>\n",
       "      <td>b6649696-43de-41f9-8914-cb8e6b20ebd5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>william</td>\n",
       "      <td>c.</td>\n",
       "      <td>leslie</td>\n",
       "      <td>...</td>\n",
       "      <td>nick1062 nick1063 nick1065 nick153 nick154</td>\n",
       "      <td>william leslie</td>\n",
       "      <td>william leslie</td>\n",
       "      <td></td>\n",
       "      <td>9372552783</td>\n",
       "      <td>wcl1043</td>\n",
       "      <td>aol.com</td>\n",
       "      <td>william.leslie2</td>\n",
       "      <td>wpafb.af.mil</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99868</th>\n",
       "      <td></td>\n",
       "      <td>1caba537-86de-4d2c-8d58-031c41b179fd</td>\n",
       "      <td></td>\n",
       "      <td>b7a5ad71-ddfb-4731-96c6-9be13f9b4576</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>steven</td>\n",
       "      <td>l</td>\n",
       "      <td>ingle</td>\n",
       "      <td>...</td>\n",
       "      <td>nick969 nick970</td>\n",
       "      <td>steven ingle</td>\n",
       "      <td>steven ingle</td>\n",
       "      <td>9564954653</td>\n",
       "      <td>2085262720</td>\n",
       "      <td>pingse</td>\n",
       "      <td>aol.com</td>\n",
       "      <td>steven.ingle</td>\n",
       "      <td>inl.gov</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99869</th>\n",
       "      <td></td>\n",
       "      <td>3efcda76-3115-4bdb-8b27-c7947058c659</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>andrew</td>\n",
       "      <td>t.</td>\n",
       "      <td>habina</td>\n",
       "      <td>...</td>\n",
       "      <td>nick68 nick69 nick70 nick311</td>\n",
       "      <td>andrew habina</td>\n",
       "      <td>andrew habina</td>\n",
       "      <td>6033510779</td>\n",
       "      <td>6172582127</td>\n",
       "      <td>ahabina</td>\n",
       "      <td>draper.com</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99870</th>\n",
       "      <td></td>\n",
       "      <td>3efcda76-3115-4bdb-8b27-c7947058c659</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>andrew</td>\n",
       "      <td>t.</td>\n",
       "      <td>habina</td>\n",
       "      <td>...</td>\n",
       "      <td>nick68 nick69 nick70 nick311</td>\n",
       "      <td>andrew habina</td>\n",
       "      <td>andrew habina</td>\n",
       "      <td>6033510779</td>\n",
       "      <td>6172582127</td>\n",
       "      <td>ahabina</td>\n",
       "      <td>draper.com</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99871 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  id_l org_person_id_l  \\\n",
       "0       874427                                106963           96887   \n",
       "1      1404715                                206379          198238   \n",
       "2        94393                                277502          358545   \n",
       "3      1419406                                288744          281663   \n",
       "4       409311                                278524          306589   \n",
       "...        ...                                   ...             ...   \n",
       "99866           e17bca27-82c2-4510-907a-847dcd1f968b                   \n",
       "99867           5077450f-d025-471c-ac08-fef9165e638a                   \n",
       "99868           1caba537-86de-4d2c-8d58-031c41b179fd                   \n",
       "99869           3efcda76-3115-4bdb-8b27-c7947058c659                   \n",
       "99870           3efcda76-3115-4bdb-8b27-c7947058c659                   \n",
       "\n",
       "                                       id_r org_person_id_r is_match prefix_l  \\\n",
       "0                                    216622          209040        1            \n",
       "1                                    254014          520751        1            \n",
       "2                                    328968          322757        1            \n",
       "3                                    288745          281664        1            \n",
       "4                                    357430          271213        1            \n",
       "...                                     ...             ...      ...      ...   \n",
       "99866  1484c243-1d4e-43d1-bf6a-5aeb6d039677                        0            \n",
       "99867  b6649696-43de-41f9-8914-cb8e6b20ebd5                        0            \n",
       "99868  b7a5ad71-ddfb-4731-96c6-9be13f9b4576                        0            \n",
       "99869                                                              0            \n",
       "99870                                                              0            \n",
       "\n",
       "        fname_l mname_l  lname_l  ...  \\\n",
       "0      nathalie           leplat  ...   \n",
       "1      karianne           fallow  ...   \n",
       "2           amy          latessa  ...   \n",
       "3      james m.            gates  ...   \n",
       "4          evan            lynch  ...   \n",
       "...         ...     ...      ...  ...   \n",
       "99866    george      r.   powers  ...   \n",
       "99867   william      c.   leslie  ...   \n",
       "99868    steven       l    ingle  ...   \n",
       "99869    andrew      t.   habina  ...   \n",
       "99870    andrew      t.   habina  ...   \n",
       "\n",
       "                                   nicks_groups_r      full_name_l  \\\n",
       "0                                                  nathalie leplat   \n",
       "1                                                  karianne fallow   \n",
       "2                                          nick64      amy latessa   \n",
       "3                                                   james m. gates   \n",
       "4                                         nick390       evan lynch   \n",
       "...                                           ...              ...   \n",
       "99866                             nick430 nick431    george powers   \n",
       "99867  nick1062 nick1063 nick1065 nick153 nick154   william leslie   \n",
       "99868                             nick969 nick970     steven ingle   \n",
       "99869                nick68 nick69 nick70 nick311    andrew habina   \n",
       "99870                nick68 nick69 nick70 nick311    andrew habina   \n",
       "\n",
       "           full_name_r clean_phone_l clean_phone_r  before_domain_l  \\\n",
       "0      nathalie leplat                  9164445155         nathalie   \n",
       "1      karianne fallow                  2083277050          kfallow   \n",
       "2          amy latessa                  8156213254      amy.latessa   \n",
       "3       james m. gates                                    jmgates46   \n",
       "4           evan lynch                  8889835441     evanlynchica   \n",
       "...                ...           ...           ...              ...   \n",
       "99866    george powell    7032988425    4152815412  george.r.powers   \n",
       "99867   william leslie                  9372552783          wcl1043   \n",
       "99868     steven ingle    9564954653    2085262720           pingse   \n",
       "99869    andrew habina    6033510779    6172582127          ahabina   \n",
       "99870    andrew habina    6033510779    6172582127          ahabina   \n",
       "\n",
       "             domain_l  before_domain_r        domain_r jaro_score  \n",
       "0            caaa.org         nathalie        caaa.org   1.000000  \n",
       "1         udidaho.org          kfallow   dairywest.com   0.560317  \n",
       "2      ideaggroup.com      amy.latessa  ideaggroup.com   1.000000  \n",
       "3        twcny.rr.com        jmgates46    twcny.rr.com   1.000000  \n",
       "4           gmail.com     evanlynchica       gmail.com   1.000000  \n",
       "...               ...              ...             ...        ...  \n",
       "99866       gmail.com    george.powell     stantec.com        NaN  \n",
       "99867         aol.com  william.leslie2    wpafb.af.mil        NaN  \n",
       "99868         aol.com     steven.ingle         inl.gov        NaN  \n",
       "99869      draper.com                             None        NaN  \n",
       "99870      draper.com                             None        NaN  \n",
       "\n",
       "[99871 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scoring match candidates based on edit distance of org names\n",
    "def score_compare(left, right, method):\n",
    "    \"\"\"\n",
    "    Given two strings, returns the comparison score based on the specified methodology.\n",
    "    \"\"\"\n",
    "    if len(left) > 0 and len(right) > 0:\n",
    "        if (method == \"jaro\"): return jaro_winkler(left, right)\n",
    "        if (method == \"fuzz-partial\"): return fuzz.partial_ratio(left, right) / 100\n",
    "        if (method == \"fuzz-sort\"): return fuzz.token_sort_ratio(left, right) / 100\n",
    "        if (method == \"fuzz-set\"): return fuzz.token_set_ratio(left, right) / 100\n",
    "        raise ValueError(\"Method {} unknown; \" \\\n",
    "                         \"must be 'jaro', 'fuzz-partial', 'fuzz-sort' or 'fuzz-set'\".format(method))\n",
    "    else: return np.nan\n",
    "\n",
    "def get_field(data, field, left_suffix='_l', right_suffix='_r'):\n",
    "    \"\"\"\n",
    "    For a list of series, this function returns a list of fields from those series.\n",
    "    So field_of('name', [row_bob, row_joe]) might return [\"Bob\", \"Joe\"].\n",
    "    \"\"\"\n",
    "    return (data[field + left_suffix], data[field + right_suffix])\n",
    "\n",
    "def org_name_score(df):\n",
    "    jaro_time = time.time()\n",
    "    df['jaro_score'] = df.apply(lambda row:\n",
    "        score_compare(*get_field(row, 'org_name'), 'jaro'),\n",
    "        axis=\"columns\")\n",
    "    print(\"\\tjaro scores done --- %s seconds ---\" % (time.time() - jaro_time))\n",
    "    \n",
    "    # consider skipping these; they have no major effect on outcomes\n",
    "    '''\n",
    "    partial_time = time.time()\n",
    "    df['fuzz_partial_score'] = df.apply(lambda row:\n",
    "        score_compare(*get_field(row, 'org_name'), 'fuzz-partial'),\n",
    "        axis=\"columns\")\n",
    "    print(\"\\tfuzz partial scores done --- %s seconds ---\" % (time.time() - partial_time))\n",
    "\n",
    "    sort_time = time.time()\n",
    "    df['fuzz_sort_score'] = df.apply(lambda row:\n",
    "        score_compare(*get_field(row, 'org_name'), 'fuzz-sort'),\n",
    "        axis=\"columns\")\n",
    "    print(\"\\tfuzz sort scores done --- %s seconds ---\" % (time.time() - sort_time))\n",
    "\n",
    "    set_time = time.time()\n",
    "    df['fuzz_set_score'] = df.apply(lambda row:\n",
    "        score_compare(*get_field(row, 'org_name'), 'fuzz-set'),\n",
    "        axis=\"columns\")\n",
    "    print(\"\\tfuzz set scores done --- %s seconds ---\" % (time.time() - set_time))\n",
    "    '''\n",
    "\n",
    "    return df\n",
    "\n",
    "org_name_score(featureless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_l</th>\n",
       "      <th>org_person_id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>org_person_id_r</th>\n",
       "      <th>is_match</th>\n",
       "      <th>prefix_l</th>\n",
       "      <th>fname_l</th>\n",
       "      <th>mname_l</th>\n",
       "      <th>lname_l</th>\n",
       "      <th>...</th>\n",
       "      <th>full_name_r</th>\n",
       "      <th>clean_phone_l</th>\n",
       "      <th>clean_phone_r</th>\n",
       "      <th>before_domain_l</th>\n",
       "      <th>domain_l</th>\n",
       "      <th>before_domain_r</th>\n",
       "      <th>domain_r</th>\n",
       "      <th>jaro_score</th>\n",
       "      <th>org_uniq</th>\n",
       "      <th>person_uniq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>874427</td>\n",
       "      <td>106963</td>\n",
       "      <td>96887</td>\n",
       "      <td>216622</td>\n",
       "      <td>209040</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>nathalie</td>\n",
       "      <td></td>\n",
       "      <td>leplat</td>\n",
       "      <td>...</td>\n",
       "      <td>nathalie leplat</td>\n",
       "      <td></td>\n",
       "      <td>9164445155</td>\n",
       "      <td>nathalie</td>\n",
       "      <td>caaa.org</td>\n",
       "      <td>nathalie</td>\n",
       "      <td>caaa.org</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1404715</td>\n",
       "      <td>206379</td>\n",
       "      <td>198238</td>\n",
       "      <td>254014</td>\n",
       "      <td>520751</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>karianne</td>\n",
       "      <td></td>\n",
       "      <td>fallow</td>\n",
       "      <td>...</td>\n",
       "      <td>karianne fallow</td>\n",
       "      <td></td>\n",
       "      <td>2083277050</td>\n",
       "      <td>kfallow</td>\n",
       "      <td>udidaho.org</td>\n",
       "      <td>kfallow</td>\n",
       "      <td>dairywest.com</td>\n",
       "      <td>0.560317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94393</td>\n",
       "      <td>277502</td>\n",
       "      <td>358545</td>\n",
       "      <td>328968</td>\n",
       "      <td>322757</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>amy</td>\n",
       "      <td></td>\n",
       "      <td>latessa</td>\n",
       "      <td>...</td>\n",
       "      <td>amy latessa</td>\n",
       "      <td></td>\n",
       "      <td>8156213254</td>\n",
       "      <td>amy.latessa</td>\n",
       "      <td>ideaggroup.com</td>\n",
       "      <td>amy.latessa</td>\n",
       "      <td>ideaggroup.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419406</td>\n",
       "      <td>288744</td>\n",
       "      <td>281663</td>\n",
       "      <td>288745</td>\n",
       "      <td>281664</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>james m.</td>\n",
       "      <td></td>\n",
       "      <td>gates</td>\n",
       "      <td>...</td>\n",
       "      <td>james m. gates</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>jmgates46</td>\n",
       "      <td>twcny.rr.com</td>\n",
       "      <td>jmgates46</td>\n",
       "      <td>twcny.rr.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409311</td>\n",
       "      <td>278524</td>\n",
       "      <td>306589</td>\n",
       "      <td>357430</td>\n",
       "      <td>271213</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>evan</td>\n",
       "      <td></td>\n",
       "      <td>lynch</td>\n",
       "      <td>...</td>\n",
       "      <td>evan lynch</td>\n",
       "      <td></td>\n",
       "      <td>8889835441</td>\n",
       "      <td>evanlynchica</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>evanlynchica</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99866</th>\n",
       "      <td></td>\n",
       "      <td>e17bca27-82c2-4510-907a-847dcd1f968b</td>\n",
       "      <td></td>\n",
       "      <td>1484c243-1d4e-43d1-bf6a-5aeb6d039677</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>george</td>\n",
       "      <td>r.</td>\n",
       "      <td>powers</td>\n",
       "      <td>...</td>\n",
       "      <td>george powell</td>\n",
       "      <td>7032988425</td>\n",
       "      <td>4152815412</td>\n",
       "      <td>george.r.powers</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>george.powell</td>\n",
       "      <td>stantec.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.298004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99867</th>\n",
       "      <td></td>\n",
       "      <td>5077450f-d025-471c-ac08-fef9165e638a</td>\n",
       "      <td></td>\n",
       "      <td>b6649696-43de-41f9-8914-cb8e6b20ebd5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>william</td>\n",
       "      <td>c.</td>\n",
       "      <td>leslie</td>\n",
       "      <td>...</td>\n",
       "      <td>william leslie</td>\n",
       "      <td></td>\n",
       "      <td>9372552783</td>\n",
       "      <td>wcl1043</td>\n",
       "      <td>aol.com</td>\n",
       "      <td>william.leslie2</td>\n",
       "      <td>wpafb.af.mil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99868</th>\n",
       "      <td></td>\n",
       "      <td>1caba537-86de-4d2c-8d58-031c41b179fd</td>\n",
       "      <td></td>\n",
       "      <td>b7a5ad71-ddfb-4731-96c6-9be13f9b4576</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>steven</td>\n",
       "      <td>l</td>\n",
       "      <td>ingle</td>\n",
       "      <td>...</td>\n",
       "      <td>steven ingle</td>\n",
       "      <td>9564954653</td>\n",
       "      <td>2085262720</td>\n",
       "      <td>pingse</td>\n",
       "      <td>aol.com</td>\n",
       "      <td>steven.ingle</td>\n",
       "      <td>inl.gov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99869</th>\n",
       "      <td></td>\n",
       "      <td>3efcda76-3115-4bdb-8b27-c7947058c659</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>andrew</td>\n",
       "      <td>t.</td>\n",
       "      <td>habina</td>\n",
       "      <td>...</td>\n",
       "      <td>andrew habina</td>\n",
       "      <td>6033510779</td>\n",
       "      <td>6172582127</td>\n",
       "      <td>ahabina</td>\n",
       "      <td>draper.com</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99870</th>\n",
       "      <td></td>\n",
       "      <td>3efcda76-3115-4bdb-8b27-c7947058c659</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>andrew</td>\n",
       "      <td>t.</td>\n",
       "      <td>habina</td>\n",
       "      <td>...</td>\n",
       "      <td>andrew habina</td>\n",
       "      <td>6033510779</td>\n",
       "      <td>6172582127</td>\n",
       "      <td>ahabina</td>\n",
       "      <td>draper.com</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99871 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  id_l org_person_id_l  \\\n",
       "0       874427                                106963           96887   \n",
       "1      1404715                                206379          198238   \n",
       "2        94393                                277502          358545   \n",
       "3      1419406                                288744          281663   \n",
       "4       409311                                278524          306589   \n",
       "...        ...                                   ...             ...   \n",
       "99866           e17bca27-82c2-4510-907a-847dcd1f968b                   \n",
       "99867           5077450f-d025-471c-ac08-fef9165e638a                   \n",
       "99868           1caba537-86de-4d2c-8d58-031c41b179fd                   \n",
       "99869           3efcda76-3115-4bdb-8b27-c7947058c659                   \n",
       "99870           3efcda76-3115-4bdb-8b27-c7947058c659                   \n",
       "\n",
       "                                       id_r org_person_id_r is_match prefix_l  \\\n",
       "0                                    216622          209040        1            \n",
       "1                                    254014          520751        1            \n",
       "2                                    328968          322757        1            \n",
       "3                                    288745          281664        1            \n",
       "4                                    357430          271213        1            \n",
       "...                                     ...             ...      ...      ...   \n",
       "99866  1484c243-1d4e-43d1-bf6a-5aeb6d039677                        0            \n",
       "99867  b6649696-43de-41f9-8914-cb8e6b20ebd5                        0            \n",
       "99868  b7a5ad71-ddfb-4731-96c6-9be13f9b4576                        0            \n",
       "99869                                                              0            \n",
       "99870                                                              0            \n",
       "\n",
       "        fname_l mname_l  lname_l  ...      full_name_r clean_phone_l  \\\n",
       "0      nathalie           leplat  ...  nathalie leplat                 \n",
       "1      karianne           fallow  ...  karianne fallow                 \n",
       "2           amy          latessa  ...      amy latessa                 \n",
       "3      james m.            gates  ...   james m. gates                 \n",
       "4          evan            lynch  ...       evan lynch                 \n",
       "...         ...     ...      ...  ...              ...           ...   \n",
       "99866    george      r.   powers  ...    george powell    7032988425   \n",
       "99867   william      c.   leslie  ...   william leslie                 \n",
       "99868    steven       l    ingle  ...     steven ingle    9564954653   \n",
       "99869    andrew      t.   habina  ...    andrew habina    6033510779   \n",
       "99870    andrew      t.   habina  ...    andrew habina    6033510779   \n",
       "\n",
       "      clean_phone_r  before_domain_l        domain_l  before_domain_r  \\\n",
       "0        9164445155         nathalie        caaa.org         nathalie   \n",
       "1        2083277050          kfallow     udidaho.org          kfallow   \n",
       "2        8156213254      amy.latessa  ideaggroup.com      amy.latessa   \n",
       "3                          jmgates46    twcny.rr.com        jmgates46   \n",
       "4        8889835441     evanlynchica       gmail.com     evanlynchica   \n",
       "...             ...              ...             ...              ...   \n",
       "99866    4152815412  george.r.powers       gmail.com    george.powell   \n",
       "99867    9372552783          wcl1043         aol.com  william.leslie2   \n",
       "99868    2085262720           pingse         aol.com     steven.ingle   \n",
       "99869    6172582127          ahabina      draper.com                    \n",
       "99870    6172582127          ahabina      draper.com                    \n",
       "\n",
       "             domain_r jaro_score org_uniq person_uniq  \n",
       "0            caaa.org   1.000000      1.0    1.000000  \n",
       "1       dairywest.com   0.560317      0.0    1.000000  \n",
       "2      ideaggroup.com   1.000000      1.0    1.000000  \n",
       "3        twcny.rr.com   1.000000      1.0    1.000000  \n",
       "4           gmail.com   1.000000      1.0    1.000000  \n",
       "...               ...        ...      ...         ...  \n",
       "99866     stantec.com        NaN      NaN    0.298004  \n",
       "99867    wpafb.af.mil        NaN      NaN    1.000000  \n",
       "99868         inl.gov        NaN      NaN    1.000000  \n",
       "99869            None        NaN      NaN    1.000000  \n",
       "99870            None        NaN      NaN    1.000000  \n",
       "\n",
       "[99871 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_names_cnt = Counter()\n",
    "person_names_cnt = Counter()\n",
    "\n",
    "def tokenize(cell):\n",
    "    \"\"\"\n",
    "    Reduces cell string contents to lowercase\n",
    "    alphanumeric characters, then splits into a list on space.\n",
    "    \n",
    "    So given one string \"  Aaa bBb ccC \", this returns [\"aaa\", \"bbb\", \"ccc\"]\n",
    "    \"\"\"\n",
    "    if cell is None: return cell\n",
    "    # For every lowercased word (from .lower.split), filter out non-alphanumeric chars\n",
    "    # and then ''.join it back together to get a list of tokens.\n",
    "    return map(lambda string: ''.join(filter(str.isalnum, string)), re.split('\\W+',cell.lower()))\n",
    "\n",
    "all_orgs = pd.DataFrame(list(featureless.org_name_l) + list(featureless.org_name_r),columns=['org_name'])\n",
    "\n",
    "def count_orgnames(df):\n",
    "    df['org_name'].dropna().apply(lambda c: org_names_cnt.update(tokenize(c)))\n",
    "\n",
    "count_orgnames(all_orgs)\n",
    "    \n",
    "def org_name_similarity(left, right):\n",
    "    def org_sequence_uniqueness(seq):\n",
    "        try:\n",
    "            return sum(1 / org_names_cnt[t.lower()] ** 0.5 for t in seq)\n",
    "        except:\n",
    "            print(seq, org_names_cnt)\n",
    "            raise ValueError()\n",
    "\n",
    "    if len(left) > 0 and len(right) > 0:\n",
    "        left_toks = set(tokenize(left))\n",
    "        right_toks = set(tokenize(right))\n",
    "\n",
    "        left_uniq = org_sequence_uniqueness(left_toks)\n",
    "        right_uniq = org_sequence_uniqueness(right_toks)\n",
    "\n",
    "        return org_sequence_uniqueness(left_toks & right_toks) / (left_uniq * right_uniq) ** 0.5\n",
    "    else: return np.nan\n",
    "\n",
    "if not organization_only:\n",
    "    all_persons = pd.DataFrame(list(featureless.full_name_l) + list(featureless.full_name_r),columns=['full_name'])\n",
    "\n",
    "    def count_personnames(df):\n",
    "        df['full_name'].dropna().apply(lambda c: person_names_cnt.update(tokenize(c)))\n",
    "    count_personnames(all_persons)\n",
    "       \n",
    "    def person_name_similarity(left, right):\n",
    "        def person_sequence_uniqueness(seq):\n",
    "            try:\n",
    "                return sum(1 / person_names_cnt[t.lower()] ** 0.5 for t in seq)\n",
    "            except:\n",
    "                print(seq, person_names_cnt)\n",
    "                raise ValueError()\n",
    "\n",
    "        if len(left) > 0 and len(right) > 0:\n",
    "            left_toks = set(tokenize(left))\n",
    "            right_toks = set(tokenize(right))\n",
    "\n",
    "            left_uniq = person_sequence_uniqueness(left_toks)\n",
    "            right_uniq = person_sequence_uniqueness(right_toks)\n",
    "\n",
    "            return person_sequence_uniqueness(left_toks & right_toks) / (left_uniq * right_uniq) ** 0.5\n",
    "        else: return np.nan\n",
    "\n",
    "def calculate_unique(df):\n",
    "    df['org_uniq'] = df.apply(lambda row:\n",
    "        org_name_similarity(*get_field(row, 'org_name')),\n",
    "        axis=\"columns\")\n",
    "    if not organization_only:\n",
    "        df['person_uniq'] = df.apply(lambda row:\n",
    "            person_name_similarity(*get_field(row, 'full_name')),\n",
    "            axis=\"columns\")\n",
    "    return df\n",
    "\n",
    "calculate_unique(featureless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCHECKING FOR STATE CODE MATCHES...\n",
      "\tstate codes checked --- 2.44 seconds ---\n",
      "\tCHECKING FOR FIRST NAME MATCHES...\n",
      "\tfname values compared --- 6.79 seconds ---\n",
      "\tCHECKING FOR NICKNAME GROUP MATCHES...\n",
      "\tnickname group matches compared --- 3.3 seconds ---\n",
      "\tCHECKING FOR MIDDLE INITIAL MATCHES...\n",
      "\tmname values compared --- 2.83 seconds ---\n",
      "\tCHECKING FOR LAST NAME MATCHES...\n",
      "\tlname values compared --- 4.22 seconds ---\n",
      "\tCHECKING FOR SUFFIX MATCHES...\n",
      "\tsuffix values compared --- 2.97 seconds ---\n",
      "\tCHECKING FOR CITY MATCHES...\n",
      "\tcity values compared --- 5.4 seconds ---\n",
      "\tCHECKING FOR POSTAL CODE MATCHES...\n",
      "\tpostal codes checked --- 6.0 seconds ---\n",
      "\tCHECKING FOR BEFORE EMAIL DOMAIN MATCHES...\n",
      "\temail before domains checked --- 3.65 seconds ---\n",
      "\tCHECKING FOR WEB DOMAIN MATCHES...\n",
      "\tweb domains checked --- 2.73 seconds ---\n",
      "\tCHECKING FOR PHONE MATCHES...\n",
      "\tphones checked --- 7.89 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def name_match(left, right):\n",
    "    left_isalnum = ''.join(e for e in left if e.isalnum()) #removing spaces and special characters from left and right\n",
    "    right_isalnum = ''.join(e for e in right if e.isalnum())\n",
    "    if len(left_isalnum) > 0 and len(right_isalnum) > 0:\n",
    "        return score_compare(left_isalnum, right_isalnum, 'jaro')\n",
    "    #elif len(left) > 0 and len(right) > 0: #we may as well still score two orgs named '$$#' and '#$$'\n",
    "        #return score_compare(left, right, 'jaro')\n",
    "    else: return np.nan\n",
    "\n",
    "def word_match(left, right): #same as name match but does not remove spaces and special characters\n",
    "    if len(left) > 0 and len(right) > 0:\n",
    "        return score_compare(left, right, 'jaro')\n",
    "    else: return np.nan\n",
    "    \n",
    "def initial_match(left, right):\n",
    "    if len(left) > 0 and len(right) > 0:\n",
    "        if left[0] == right[0]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "personal_suffixes = ['ii','iii','iv','v','jr','sr']\n",
    "def suffix_match(left, right):\n",
    "    if len(left) > 0 and len(right) > 0:\n",
    "        l_suffix = left.replace('.','').replace(',','').split()\n",
    "        l_personal_suffix = set.intersection(set(l_suffix),personal_suffixes)\n",
    "        if len(l_personal_suffix) > 0:\n",
    "            r_suffix = right.replace('.','').replace(',','').split()\n",
    "            r_personal_suffix = set.intersection(set(r_suffix),personal_suffixes)\n",
    "            if len(r_personal_suffix) > 0:\n",
    "                if (len(set.intersection(l_personal_suffix,r_personal_suffix)) > 0):\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return np.nan\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "featureless = featureless.fillna('')   \n",
    "def match_fields(candidata):\n",
    "    if 'state_l' in candidata:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR STATE CODE MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        def state_match(left, right):\n",
    "            if len(left) >=2 and len(right) >= 2:\n",
    "                if left == right:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return np.nan\n",
    "            \n",
    "        candidata['state_match'] = candidata.apply(lambda row:\n",
    "            state_match(*get_field(row, 'state')),\n",
    "            axis=\"columns\")\n",
    "        \n",
    "        print(\"\\tstate codes checked --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'fname_l' in candidata and not organization_only:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR FIRST NAME MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        candidata['fname_match'] = candidata.apply(lambda row:\n",
    "            name_match(*get_field(row, 'fname')),\n",
    "            axis=\"columns\")\n",
    "\n",
    "        #check if first initials match\n",
    "        candidata['f_initial_match'] = candidata.apply(lambda row:\n",
    "            initial_match(*get_field(row, 'fname')),\n",
    "            axis='columns')\n",
    "        \n",
    "        print(\"\\tfname values compared --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "        \n",
    "        # If l_fname is present then the nick group should be too\n",
    "        start_time = time.time()\n",
    "        print(\"\\tCHECKING FOR NICKNAME GROUP MATCHES...\")\n",
    "\n",
    "        # This is a little complicated, but essentially it counts how many nicks groups are shared:\n",
    "        #\n",
    "        # get_field(row, 'nicks_groups'):\n",
    "        #     look up the data for each row, and get the nicks_groups from the left and right.\n",
    "        # map(lambda nicks: set(nicks.split()), _):\n",
    "        #     for the left and right nicks in nicks_groups, split it and create a set of nick groups\n",
    "        # set.intersection(*_):\n",
    "        #     pass these two sets to set.intersection to get the intersection of the two\n",
    "        # len(_):\n",
    "        #     take the length of the intersection\n",
    "        \n",
    "        #changed to a 0/1 flag rather then len of intersection\n",
    "        def nick_match(left, right):\n",
    "            if len(left) > 4 and len(right) > 4:\n",
    "                if len(set.intersection(set(left.split()),set(right.split()))) > 0:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return np.nan\n",
    "        candidata['nick_matches'] = candidata.apply(lambda row:\n",
    "                                                         nick_match(*get_field(row, 'nicks_groups')),\n",
    "                                                         axis='columns')\n",
    "        print('\\tnickname group matches compared --- %s seconds ---' % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'mname_l' in candidata and not organization_only:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR MIDDLE INITIAL MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        \n",
    "        candidata['m_initial_match'] = candidata.apply(lambda row:\n",
    "            initial_match(*get_field(row, 'mname')),\n",
    "            axis='columns')\n",
    "        \n",
    "        print(\"\\tmname values compared --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "        \n",
    "    if 'lname_l' in candidata and not organization_only:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR LAST NAME MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        candidata['lname_match'] = candidata.apply(lambda row:\n",
    "            name_match(*get_field(row, 'lname')),\n",
    "            axis=\"columns\")\n",
    "\n",
    "        print(\"\\tlname values compared --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'suffix_l' in candidata and not organization_only:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR SUFFIX MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        \n",
    "        candidata['suffix_match'] = candidata.apply(lambda row:\n",
    "            suffix_match(*get_field(row, 'suffix')),\n",
    "            axis='columns')\n",
    "        \n",
    "        print(\"\\tsuffix values compared --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "    if 'city_l' in candidata:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR CITY MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        candidata['city_match'] = candidata.apply(lambda row:\n",
    "            name_match(*get_field(row, 'city')),\n",
    "            axis=\"columns\")\n",
    "        print(\"\\tcity values compared --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'zip_l' in candidata:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR POSTAL CODE MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        def postal_similarity(left, right):\n",
    "            # if the number is too short, means it's fubar\n",
    "            if len(left) >= 5 and len(right) >= 5:\n",
    "                if max(len(sub) for sub in find_common_subsequences(left, right)) / 5 >= 1:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        candidata['zip_match'] = candidata.apply(lambda row:\n",
    "            postal_similarity(*get_field(row, 'zip')),\n",
    "            axis=\"columns\")\n",
    "\n",
    "        print(\"\\tpostal codes checked --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'before_domain_l' in candidata and not organization_only:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR BEFORE EMAIL DOMAIN MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        candidata['before_domain_match'] = candidata.apply(lambda row:\n",
    "            word_match(*get_field(row, 'before_domain')),\n",
    "            axis=\"columns\")\n",
    "\n",
    "        print(\"\\temail before domains checked --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'domain_l' in candidata:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR WEB DOMAIN MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        def domain_match(left, right):\n",
    "            if len(left) > 4 and len(right) > 4:\n",
    "                if left == right:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        candidata['domain_match'] = candidata.apply(lambda row:\n",
    "            domain_match(*get_field(row, 'domain')),\n",
    "            axis=\"columns\")\n",
    "\n",
    "        print(\"\\tweb domains checked --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "\n",
    "    if 'clean_phone_l' in candidata:\n",
    "        start_time = time.time()\n",
    "        print (\"\\tCHECKING FOR PHONE MATCHES...\") #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        #scoring match candidates based on matching phone\n",
    "        def phone_simularity(left, right):\n",
    "            if len(left) > 9 and len(right) > 9:\n",
    "                if max(len(sub) for sub in find_common_subsequences(left, right)) / 10 >= 1:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        candidata['phone_match'] = candidata.apply(lambda row:\n",
    "            phone_simularity(*get_field(row, 'clean_phone')),\n",
    "            axis=\"columns\")\n",
    "\n",
    "        print(\"\\tphones checked --- %s seconds ---\" % round(time.time() - start_time, 2))\n",
    "    \n",
    "    return candidata\n",
    "\n",
    "match_fields(featureless)\n",
    "\n",
    "featureless.to_csv('training_records_w_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute null training feature values\n",
    "possible_features = [\n",
    "    'jaro_score',\n",
    "    'fuzz_partial_score',\n",
    "    'fuzz_sort_score',\n",
    "    'fuzz_set_score',\n",
    "    'org_uniq',\n",
    "    'city_match',\n",
    "    'state_match',\n",
    "    'zip_match',\n",
    "    'domain_match',\n",
    "    'fname_match',\n",
    "    'f_initial_match',\n",
    "    'm_initial_match',\n",
    "    'lname_match',\n",
    "    'suffix_match',\n",
    "    'person_uniq',\n",
    "    'nick_matches',\n",
    "    'phone_match',\n",
    "    'before_domain_match',\n",
    "]\n",
    "\n",
    "# Get the columns that are features and are also present in our dataset right now\n",
    "present_columns = pd.read_csv('training_records_w_features.csv', nrows=1).columns\n",
    "\n",
    "present_features = present_columns[present_columns.isin(possible_features)]\n",
    "\n",
    "#imputing np.nan values in ML features.  we need to do this because we want the model to treat differently\n",
    "#cases where two records have a data type present and it DOES NOT MATCH and where one record is simply MISSING that data\n",
    "\n",
    "#creating a dictionary we will use to determine the value to impute into feature NULLs\n",
    "feature_avg_dict= {}\n",
    "for feature in present_features:\n",
    "    feature_df = pd.read_csv('training_records_w_features.csv',usecols=[feature])\n",
    "    avg = feature_df[feature_df[feature].notnull()].mean()[0]\n",
    "    feature_avg_dict.update({feature:avg})\n",
    "\n",
    "def impute_nulls(candidata):\n",
    "    for feature in present_features:\n",
    "        candidata[feature] = candidata[feature].fillna(feature_avg_dict[feature])\n",
    "        #candidata[feature] = candidata[feature].replace(np.nan,feature_avg_dict[feature])\n",
    "\n",
    "    return candidata\n",
    "\n",
    "impute_nulls(featureless)\n",
    "\n",
    "if organization_only:\n",
    "    featureless.to_csv('org_training_records_w_imputed_features.csv',index=False)\n",
    "else:\n",
    "    featureless.to_csv('person_training_records_w_imputed_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaro_score</th>\n",
       "      <th>org_uniq</th>\n",
       "      <th>person_uniq</th>\n",
       "      <th>state_match</th>\n",
       "      <th>fname_match</th>\n",
       "      <th>f_initial_match</th>\n",
       "      <th>nick_matches</th>\n",
       "      <th>m_initial_match</th>\n",
       "      <th>lname_match</th>\n",
       "      <th>suffix_match</th>\n",
       "      <th>city_match</th>\n",
       "      <th>zip_match</th>\n",
       "      <th>before_domain_match</th>\n",
       "      <th>domain_match</th>\n",
       "      <th>phone_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.624292</td>\n",
       "      <td>0.154514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560317</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.624292</td>\n",
       "      <td>0.154514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.624292</td>\n",
       "      <td>0.154514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99866</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99867</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99868</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.573810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99869</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.154514</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99870</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99871 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      jaro_score org_uniq  person_uniq  state_match  fname_match  \\\n",
       "0              1        1     1.000000     0.406778          1.0   \n",
       "1       0.560317        0     1.000000     1.000000          1.0   \n",
       "2              1        1     1.000000     1.000000          1.0   \n",
       "3              1        1     1.000000     0.406778          1.0   \n",
       "4              1        1     1.000000     0.406778          1.0   \n",
       "...          ...      ...          ...          ...          ...   \n",
       "99866                         0.298004     0.000000          1.0   \n",
       "99867                         1.000000     0.000000          1.0   \n",
       "99868                         1.000000     0.000000          1.0   \n",
       "99869                         1.000000     0.000000          1.0   \n",
       "99870                         1.000000     0.000000          1.0   \n",
       "\n",
       "       f_initial_match  nick_matches  m_initial_match  lname_match  \\\n",
       "0                    1      0.097181         0.122594     1.000000   \n",
       "1                    1      0.097181         0.122594     1.000000   \n",
       "2                    1      1.000000         0.122594     1.000000   \n",
       "3                    1      0.097181         0.122594     1.000000   \n",
       "4                    1      1.000000         0.122594     1.000000   \n",
       "...                ...           ...              ...          ...   \n",
       "99866                1      1.000000         0.000000     0.866667   \n",
       "99867                1      1.000000         0.000000     1.000000   \n",
       "99868                1      1.000000         0.000000     1.000000   \n",
       "99869                1      1.000000         0.000000     1.000000   \n",
       "99870                1      1.000000         0.000000     1.000000   \n",
       "\n",
       "       suffix_match  city_match  zip_match  before_domain_match  domain_match  \\\n",
       "0          0.082011    0.624292   0.154514             1.000000      1.000000   \n",
       "1          0.082011    1.000000   1.000000             1.000000      0.000000   \n",
       "2          0.082011    1.000000   1.000000             1.000000      1.000000   \n",
       "3          0.082011    0.624292   0.154514             1.000000      1.000000   \n",
       "4          0.082011    0.624292   0.154514             1.000000      1.000000   \n",
       "...             ...         ...        ...                  ...           ...   \n",
       "99866      0.082011    0.405556   1.000000             0.915897      0.000000   \n",
       "99867      0.082011    0.500000   0.000000             0.473016      0.000000   \n",
       "99868      0.082011    0.573810   0.000000             0.416667      0.000000   \n",
       "99869      0.082011    0.671958   0.154514             0.473077      0.021356   \n",
       "99870      0.082011    0.671958   0.000000             0.473077      0.021356   \n",
       "\n",
       "       phone_match  \n",
       "0         0.004071  \n",
       "1         0.004071  \n",
       "2         0.004071  \n",
       "3         0.004071  \n",
       "4         0.004071  \n",
       "...            ...  \n",
       "99866     0.000000  \n",
       "99867     0.004071  \n",
       "99868     0.000000  \n",
       "99869     0.000000  \n",
       "99870     0.000000  \n",
       "\n",
       "[99871 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = featureless[['jaro_score', 'org_uniq', 'person_uniq', 'state_match',\n",
    "       'fname_match', 'f_initial_match', 'nick_matches', 'm_initial_match',\n",
    "       'lname_match', 'suffix_match', 'city_match', 'zip_match',\n",
    "       'before_domain_match', 'domain_match', 'phone_match']]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[features.jaro_score !='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "features['jaro_score'] = features['jaro_score'].astype(float)\n",
    "features['org_uniq'] = features['org_uniq'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaro_score             float64\n",
       "org_uniq               float64\n",
       "person_uniq            float64\n",
       "state_match            float64\n",
       "fname_match            float64\n",
       "f_initial_match          int64\n",
       "nick_matches           float64\n",
       "m_initial_match        float64\n",
       "lname_match            float64\n",
       "suffix_match           float64\n",
       "city_match             float64\n",
       "zip_match              float64\n",
       "before_domain_match    float64\n",
       "domain_match           float64\n",
       "phone_match            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=7, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "k=7\n",
    "kmeans = cluster.KMeans(n_clusters=k)\n",
    "kmeans.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [6 6 6 ... 3 6 6]\n",
      "\n",
      "Centroids: [[ 6.32186560e-01  4.93504081e-02  1.61408666e-02  3.34886186e-01\n",
      "   6.10746614e-01  1.00000000e+00  4.68583690e-02  1.21126663e-01\n",
      "   4.91928615e-01  8.20319573e-02  5.79800606e-01  5.56481072e-02\n",
      "   5.07556387e-01  8.09169711e-03  2.56963140e-03]\n",
      " [ 5.97437281e-01  2.98571933e-02  2.24129534e-03  1.00000000e+00\n",
      "   5.08079314e-01 -3.07809334e-14  4.93481628e-02  1.20628726e-01\n",
      "   5.01490607e-01  8.21044673e-02  7.39842793e-01  1.21348707e-03\n",
      "   4.62200845e-01  8.64873684e-03  1.96925487e-03]\n",
      " [ 6.32499569e-01  4.62711401e-02  4.38978872e-03 -1.43940415e-13\n",
      "   5.06477458e-01 -4.97102359e-14  4.83309175e-02  1.20862661e-01\n",
      "   5.03602747e-01  8.21160486e-02  4.86274670e-01  9.80785129e-03\n",
      "   4.57034694e-01  7.37906471e-03  1.94828685e-03]\n",
      " [ 5.72964388e-01  1.48187242e-02  2.08545860e-01  2.84612205e-01\n",
      "   9.80140530e-01  9.99742135e-01  1.00000000e+00  1.28423878e-01\n",
      "   4.41934577e-01  7.62747939e-02  5.90874529e-01  9.42323248e-02\n",
      "   5.14874328e-01  1.00463874e-02  3.02180911e-03]\n",
      " [ 5.86691719e-01  3.07852385e-02  1.55445714e-03  1.00000000e+00\n",
      "   5.15143334e-01  9.55828350e-02  4.83951974e-02  1.20423709e-01\n",
      "   4.99076638e-01  8.21687959e-02  9.80583870e-01  1.00000000e+00\n",
      "   4.67877290e-01  1.78109156e-02  7.51814406e-03]\n",
      " [ 6.65676199e-01  7.88770474e-02  7.39263160e-03  3.99781570e-01\n",
      "   5.04093267e-01 -3.99125177e-14  4.80686579e-02  1.20484270e-01\n",
      "   5.07116287e-01  8.20105820e-02  6.22256809e-01  1.69055926e-01\n",
      "   4.60863875e-01  1.10664255e-02  3.76353252e-03]\n",
      " [ 9.83935644e-01  9.60206603e-01  9.30330628e-01  6.45705647e-01\n",
      "   9.67525151e-01  9.74174174e-01  7.30485346e-01  2.13488899e-01\n",
      "   9.80674122e-01  8.99852233e-02  7.73314879e-01  4.82121955e-01\n",
      "   8.50780081e-01  7.09188409e-01  6.48925637e-02]]\n",
      "\n",
      "Inertia: 13552.947357782507\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "inertia = kmeans.inertia_\n",
    "\n",
    "print('Labels:', labels)\n",
    "print('')\n",
    "print('Centroids:', centroids)\n",
    "print('')\n",
    "print('Inertia:', inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "featureless_reduced = featureless[featureless.jaro_score !=''] #need to do this to avoid shape error\n",
    "featureless_reduced['cluster_k7'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    36522\n",
       "5    22850\n",
       "1    16935\n",
       "4     9531\n",
       "0     8416\n",
       "3     3878\n",
       "6     1665\n",
       "Name: cluster_k7, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureless_reduced.cluster_k7.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-964b361eed0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatureless_reduced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'cluster'"
     ]
    }
   ],
   "source": [
    "featureless_reduced.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureless_reduced[featureless_reduced.is_match == '1'].cluster_k7.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureless_reduced.to_csv('person training w imputed features & clustered k15.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
