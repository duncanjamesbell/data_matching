{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from jellyfish import jaro_winkler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from py_common_subseq import find_common_subsequences\n",
    "import numbers\n",
    "import time\n",
    "from collections import Counter \n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import shutil\n",
    "\n",
    "with io.open('recipients_reduced.csv', encoding='utf-8', errors='ignore') as source:\n",
    "    with io.open('recipients_reduced_utf.csv', mode='w', encoding='utf-8') as target:\n",
    "        shutil.copyfileobj(source,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING INITIAL DATAFRAME...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "File RecipientTableUpdated_1.30.19_utf.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-491632919e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"LOADING INITIAL DATAFRAME...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RecipientTableUpdated_1.30.19_utf.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0morg_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morg_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'org_name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morg_address1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'address1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morg_city\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morg_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morg_zip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'postal_code'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morg_web\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'web'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dbell\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dbell\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dbell\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dbell\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dbell\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File RecipientTableUpdated_1.30.19_utf.csv does not exist"
     ]
    }
   ],
   "source": [
    "#define column names\n",
    "org_id = 'Recipient_ID'\n",
    "org_name = 'RecipientName'\n",
    "org_address1 = 'AddressLine1Txt'\n",
    "org_city = 'CityNm'\n",
    "org_state = 'StateAbbreviationCd'\n",
    "org_zip = 'Zip'\n",
    "org_web = 'WebsiteAddressTxt'\n",
    "\n",
    "#set parameters\n",
    "token_match_min = 2 # minimum number of matched tokens to be considered a match\n",
    "token_limiter = .99 # percent of non-single tokens to tokenize, where rare tokens are at the bottom and common at the top\n",
    "name_weight = .75 #note that this is really .75 * 4 because there are 4 org name simularity metrics\n",
    "state_weight = 1\n",
    "zip_weight = 1\n",
    "phone_weight = 1\n",
    "composite_score_min = 3.5 #minimum composite match score to be considered a match\n",
    "\n",
    "start_time = time.time()\n",
    "print \"LOADING INITIAL DATAFRAME...\"\n",
    "\n",
    "df = pd.read_csv('RecipientTableUpdated_1.30.19_utf.csv',keep_default_na=False)\n",
    "\n",
    "df.rename(columns={org_id:'id',org_name:'org_name',org_address1:'address1',org_city:'city',org_state:'state',org_zip:'postal_code',org_web:'web'}, inplace=True)\n",
    "\n",
    "print(\"Dataframe loaded --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"PRE-PROCESSING: NORMALIZE STATES...\"\n",
    "#normalize state codes\n",
    "state_lkup = pd.read_csv('state_lkup.csv',keep_default_na=False)\n",
    "\n",
    "from collections import defaultdict\n",
    "state_dict = defaultdict(list)\n",
    "for state, acronym in zip(state_lkup.state.values,state_lkup.acronym.values):\n",
    "    state_dict[state].append(acronym)\n",
    "\n",
    "df.state = df.state.str.lower()\n",
    "df.state = df.state.replace(state_dict)\n",
    "df.to_csv('org_dup_df.csv')\n",
    "\n",
    "print(\"states normalized --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "chunking_time = time.time()\n",
    "print \"TOKENIZING, IDENTIFYING CANDIDATE MATCH PAIRS...\"\n",
    "\n",
    "n=0\n",
    "dfs_list = []\n",
    "for df in pd.read_csv('org_dup_df.csv',keep_default_na=False,chunksize=10000):\n",
    "    \n",
    "    n=n+1\n",
    "    start_time = time.time()\n",
    "    print n\n",
    "    \n",
    "    left_df_chunk = df.copy()\n",
    "    left_df_chunk.rename(columns={'org_name':'l_org_name','address1':'l_address1','city':'l_city','state':'l_state','postal_code':'l_postal_code','web':'l_web'}, inplace=True)\n",
    "\n",
    "        # for the left dataset\n",
    "    left_tokenized_columns = [\n",
    "        'l_org_name',\n",
    "        #'l_acronym',\n",
    "        #'l_alt_name',\n",
    "        #'l_address1',\n",
    "        #'l_address2',\n",
    "        'l_city', \n",
    "        'l_state', \n",
    "        'l_postal_code',\n",
    "        'l_web' \n",
    "        #'l_phone'\n",
    "    ]\n",
    "\n",
    "    # lowercase the name and split on spaces, remove non-alphanumeric chars\n",
    "    def tokenize_name(name):\n",
    "        if isinstance(name, basestring) is True:\n",
    "            clean_name = ''.join(c if c.isalnum() else ' ' for c in name)\n",
    "            return clean_name.lower().split()\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    unique_tokens = [] #we treat state and zips differently because we want to include ALl state and zip tokens as these are unique\n",
    "\n",
    "    #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< add chosen unique columns here from each df\n",
    "    for word in left_df_chunk['l_state']:\n",
    "        if isinstance(word, float) is False:\n",
    "            unique_tokens.append(tokenize_name(str(word)))\n",
    "\n",
    "    for word in left_df_chunk['l_postal_code']:\n",
    "        if isinstance(word, float) is False:\n",
    "            unique_tokens.append(tokenize_name(str(word)))\n",
    "\n",
    "    #for word in left_df_chunk['l_acronym']:\n",
    "    #    if isinstance(word, float) is False:\n",
    "    #        unique_tokens.append(tokenize_name(str(word)))\n",
    "\n",
    "    #for word in left_df_chunk['l_phone']:\n",
    "    #    if isinstance(word, float) is False:\n",
    "    #        unique_tokens.append(tokenize_name(str(word)))\n",
    "    #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "    unique_flat_list = [item for sublist in unique_tokens for item in sublist]\n",
    "\n",
    "    #instantiate counter and use to count word frequencies in flat list\n",
    "    u_cnt = Counter()\n",
    "    for token in unique_flat_list:\n",
    "        u_cnt[token] += 1\n",
    "\n",
    "    u_cnt_dict = dict(u_cnt) #convert to dictionary\n",
    "\n",
    "    unique_tokens_df = pd.DataFrame(u_cnt_dict.items(), columns=['token', 'count'])\n",
    "    unique_tokens_df = unique_tokens_df.sort_values(by='count')  #sorting by count so that we can take the first x% of tokens by rare frequency\n",
    "\n",
    "    unique_token_flag = []\n",
    "    for index, value in enumerate(unique_tokens_df['count']):\n",
    "        if value == 1:\n",
    "            unique_token_flag.append(0)  #for any tokens occuring only once, we exclude\n",
    "        else:\n",
    "            unique_token_flag.append(1)\n",
    "\n",
    "    unique_tokens_df['flag'] = unique_token_flag        \n",
    "\n",
    "    all_other_words = [] #creating a list of all words used in just ONE of the dfs in selected columns, for counting to determine rarity\n",
    "\n",
    "    for word in left_df_chunk['l_org_name']:\n",
    "        if isinstance(word, float) is False:\n",
    "            all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "    #for word in left_df_chunk['l_alt_name']:\n",
    "    #    if isinstance(word, float) is False:\n",
    "    #        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "    #for word in left_df_chunk['l_address1']:\n",
    "    #    if isinstance(word, float) is False:\n",
    "    #        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "    for word in left_df_chunk['l_city']:\n",
    "        if isinstance(word, float) is False:\n",
    "            all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "    for word in left_df_chunk['l_web']:\n",
    "        if isinstance(word, float) is False:\n",
    "            all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "    flat_list = [item for sublist in all_other_words for item in sublist] #flatten list so it can be counted\n",
    "\n",
    "    #instantiate counter and use to count word frequencies in flat list\n",
    "    cnt = Counter()\n",
    "    for token in flat_list:\n",
    "        cnt[token] += 1\n",
    "\n",
    "    cnt_dict = dict(cnt) #convert to dictionary\n",
    "\n",
    "    main_tokens_df = pd.DataFrame(cnt_dict.items(), columns=['token', 'count'])\n",
    "    main_tokens_df = main_tokens_df.sort_values(by='count')  #sorting by count so that we can take the first x% of tokens by rare frequency\n",
    "\n",
    "    main_token_flag = []\n",
    "    for index, value in enumerate(main_tokens_df['count']):\n",
    "        if value == 1:\n",
    "            main_token_flag.append(0)  #for any tokens occuring only once, we exclude\n",
    "        elif index < int(main_tokens_df.shape[0] * token_limiter): #important line, we are cutting the top x% of frequently occuring tokens\n",
    "            main_token_flag.append(1)\n",
    "        else:\n",
    "            main_token_flag.append(0)  #for the most common tokens, we exclude\n",
    "\n",
    "    main_tokens_df['flag'] = main_token_flag\n",
    "\n",
    "    all_tokens = pd.concat([unique_tokens_df, main_tokens_df])\n",
    "\n",
    "    all_tokens.drop('count',axis=1,inplace=True)\n",
    "    all_tokens['flag'] = all_tokens.flag.astype(int) #converting flags to int\n",
    "    tokens_dct = all_tokens.to_dict('split') #converting tokens_df to dictionary\n",
    "    tokens_dct=dict(tokens_dct['data']) #honestly can't remember why this works, something to do with conversion to dictionary\n",
    "\n",
    "    #preparing token_ids which will be used for joining left and right dfs\n",
    "    all_tokens.sort_values(by='flag',ascending=False,inplace=True)\n",
    "    all_tokens.drop_duplicates(subset='token',keep='first',inplace=True)\n",
    "    token_ids = all_tokens.index.get_level_values(0)\n",
    "    all_tokens['token_id'] = token_ids\n",
    "\n",
    "    all_tokens.drop('flag',axis=1,inplace=True)\n",
    "    all_tokens['token_id'] = all_tokens.token_id.astype(int)\n",
    "    token_id_dct = all_tokens.to_dict('split')\n",
    "    tokens_id_dct=dict(token_id_dct['data'])\n",
    "    \n",
    "    vocabulary = np.array([w for w, c in tokens_dct.items() if c ==1]) #this works even without the ==1 and I don't know why\n",
    "    cv = CountVectorizer( vocabulary=vocabulary)\n",
    "\n",
    "    frame_list = []\n",
    "    for colname in left_tokenized_columns:\n",
    "        tokenmapping = cv.fit_transform(left_df_chunk[colname])\n",
    "        df_row, token_id = tokenmapping.nonzero()\n",
    "\n",
    "        frame_list.append(pd.DataFrame(np.vstack([vocabulary[token_id], left_df_chunk['id'].values[df_row]]).T, columns = ['token', 'id']))\n",
    "\n",
    "    left_keyed = pd.concat(frame_list)\n",
    "\n",
    "    #append token_id to token as this will be more efficient to join with\n",
    "    left_token_ids = []\n",
    "    for token in left_keyed.token:\n",
    "        left_token_ids.append(tokens_id_dct[token])\n",
    "\n",
    "    left_keyed['token_id'] = left_token_ids\n",
    "    left_keyed.sort_values(by='token_id',inplace=True)\n",
    "    left_keyed.set_index('token_id',inplace=True)\n",
    "    left_keyed.drop('token',axis=1,inplace=True)\n",
    "\n",
    "    aggregations = {\n",
    "        'id_l': 'count'\n",
    "    }\n",
    "    \n",
    "    right_keyed = left_keyed.copy()\n",
    "    joined = left_keyed.join(right_keyed, how='inner',lsuffix='_l',rsuffix='_r')\n",
    "    keys_grouped = joined.groupby(by=['id_l', 'id_r']).agg(aggregations)\n",
    "    keys_grouped.rename(columns={'id_l':'id_l count'}, inplace=True)\n",
    "    matched_records = keys_grouped[keys_grouped['id_l count'] >= token_match_min]\n",
    "    matched_records.reset_index(inplace=True)\n",
    "    duplicate_candidates = matched_records[matched_records['id_l'] <> matched_records['id_r']]\n",
    "    \n",
    "    #add chunk duplicate candidates to df list\n",
    "    dfs_list.append(duplicate_candidates)\n",
    "    \n",
    "    print(\"chunk loaded --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "dup_dfs = pd.concat(dfs_list)\n",
    "print(\"All chunks loaded --- %s seconds ---\" % (time.time() - chunking_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"REMOVING REDUNDANT DUPLICATE ID PAIRS...\"\n",
    "\n",
    "match_tuples = list(zip(dup_dfs['id_l'], dup_dfs['id_r']))\n",
    "\n",
    "sorted_match_tuples = []\n",
    "for tup in match_tuples:\n",
    "    s = tuple(sorted(tup))\n",
    "    sorted_match_tuples.append(s)\n",
    "\n",
    "dup_dfs.drop(['id_l','id_r'],axis=1,inplace=True)\n",
    "dup_dfs['id_tuples'] = sorted_match_tuples\n",
    "\n",
    "new_col_list = ['id_l','id_r']\n",
    "for n,col in enumerate(new_col_list):\n",
    "    dup_dfs[col] = dup_dfs['id_tuples'].apply(lambda location: location[n])\n",
    "    \n",
    "dup_dfs.drop('id_tuples',axis=1,inplace=True)\n",
    "dup_dfs.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"redundant id pairs removed --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"APPENDING ORIGINAL DATA TO MATCH CANDIDATES...\"\n",
    "\n",
    "left_df = pd.read_csv('org_dup_df.csv')\n",
    "right_df = left_df.copy()\n",
    "left_df.rename(columns={'id':'id_l','org_name':'l_org_name','address1':'l_address1','city':'l_city','state':'l_state','postal_code':'l_postal_code','web':'l_web'}, inplace=True)\n",
    "right_df.rename(columns={'id':'id_r','org_name':'r_org_name','address1':'r_address1','city':'r_city','state':'r_state','postal_code':'r_postal_code','web':'r_web'}, inplace=True)\n",
    "\n",
    "#creating left/right dataframes which contain only the most relevant details for reviewing the match strengths\n",
    "left_match_data = left_df[['id_l','l_org_name','l_city','l_state','l_postal_code','l_web']].copy()\n",
    "right_match_data = right_df[['id_r','r_org_name','r_city','r_state','r_postal_code','r_web']].copy()\n",
    "\n",
    "#making sure keys are str, results in blank df otherwise\n",
    "left_match_data.id_l = left_match_data.id_l.astype('str')\n",
    "right_match_data.id_r = right_match_data.id_r.astype('str')\n",
    "dup_dfs.id_l = dup_dfs.id_l.astype('str')\n",
    "dup_dfs.id_r = dup_dfs.id_r.astype('str')\n",
    "\n",
    "#merging matched_records df with original record data for ease of review\n",
    "l_conc = pd.merge(dup_dfs, left_match_data, on='id_l')\n",
    "full_conc = pd.merge(l_conc, right_match_data, on='id_r')\n",
    "\n",
    "print(\"original data concatenated with matches --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"SCORING ORG NAME SIMULARITY...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#scoring match candidates based on edit distance of org names\n",
    "def jaro_simularity(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return jaro_winkler(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '')\n",
    "def fuzz_partial(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return fuzz.partial_ratio(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '') / float(100)\n",
    "def fuzz_sort(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return fuzz.token_sort_ratio(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '') / float(100)\n",
    "def fuzz_set(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return fuzz.token_set_ratio(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '') / float(100)\n",
    "\n",
    "full_conc['l_org_name'] = full_conc['l_org_name'].astype('str')\n",
    "full_conc['r_org_name'] = full_conc['r_org_name'].astype('str')\n",
    "\n",
    "jaro_time = time.time()\n",
    "full_conc['jaro_score'] = full_conc.apply(lambda x: jaro_simularity(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"jaro scores done --- %s seconds ---\" % (time.time() - jaro_time))\n",
    "partial_time = time.time()\n",
    "full_conc['fuzz_partial_score'] = full_conc.apply(lambda x: fuzz_partial(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"fuzz partial scores done --- %s seconds ---\" % (time.time() - partial_time))\n",
    "sort_time = time.time()\n",
    "full_conc['fuzz_sort_score'] = full_conc.apply(lambda x: fuzz_sort(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"fuzz sort scores done --- %s seconds ---\" % (time.time() - sort_time))\n",
    "set_time = time.time()\n",
    "full_conc['fuzz_set_score'] = full_conc.apply(lambda x: fuzz_set(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"fuzz set scores done --- %s seconds ---\" % (time.time() - set_time))\n",
    "print \"\"\n",
    "\n",
    "print(\"name simularity scored --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"CHECKING FOR STATE CODE MATCHES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "def sanitize_state(state):\n",
    "    if isinstance(state,basestring) is True:\n",
    "        return ''.join(c for c in (state or '') if c in 'abcdefghijklmnopqrstuvwxyz')\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def state_match(state_a, state_b):\n",
    "    sanitized_state_a = str(sanitize_state(state_a))\n",
    "    sanitized_state_b = str(sanitize_state(state_b))\n",
    "\n",
    "    # if the value is too short, means it's fubar\n",
    "    if len(sanitized_state_a) < 2 or len(sanitized_state_b) < 2:\n",
    "        return 0\n",
    "    if state_a == state_b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "full_conc['state_match'] = full_conc.apply(lambda x: state_match(x.l_state, x.r_state), axis=1)\n",
    "\n",
    "print(\"state codes checked --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"CHECKING FOR POSTAL CODE MATCHES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#scoring match candidates based on matching postal code\n",
    "\n",
    "def sanitize_postal(postal):\n",
    "    if isinstance(postal, basestring) is True:\n",
    "        return ''.join(c for c in (postal or '') if c in '1234567890')\n",
    "    if isinstance(postal, float) is False:\n",
    "        return postal\n",
    "\n",
    "def postal_simularity(postal_a, postal_b):\n",
    "    sanitized_postal_a = str(sanitize_postal(postal_a))\n",
    "    sanitized_postal_b = str(sanitize_postal(postal_b))\n",
    "\n",
    "    # if the number is too short, means it's fubar\n",
    "    if len(sanitized_postal_a) < 5 or len(sanitized_postal_b) < 5:\n",
    "        return 0\n",
    "    if float(max(len(sub) for sub in find_common_subsequences(sanitized_postal_a, sanitized_postal_b))) / 5 >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "full_conc['zip_match'] = full_conc.apply(lambda x: postal_simularity(x.l_postal_code, x.r_postal_code), axis=1)\n",
    "    \n",
    "print(\"postal codes checked --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "#start_time = time.time()\n",
    "#print \"CHECKING FOR PHONE MATCHES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#scoring match candidates based on matching postal code\n",
    "\n",
    "#def sanitize_phone(phone):\n",
    "#    if isinstance(phone, basestring) is True:\n",
    "#        return ''.join(c for c in (phone or '') if c in '1234567890')\n",
    "#    if isinstance(phone, float) is False:\n",
    "#        return phone\n",
    "\n",
    "#def postal_simularity(phone_a, phone_b):\n",
    "#    sanitized_phone_a = str(sanitize_phone(phone_a))\n",
    "#    sanitized_phone_b = str(sanitize_phone(phone_b))\n",
    "\n",
    "    # if the number is too short, means it's fubar\n",
    "#    if len(sanitized_phone_a) < 10 or len(sanitized_phone_b) < 10:\n",
    "#        return 0\n",
    "#    if float(max(len(sub) for sub in find_common_subsequences(sanitized_phone_a, sanitized_phone_b))) / 10 >= 1:\n",
    "#        return 1\n",
    "#    else:\n",
    "#        return 0\n",
    "    \n",
    "#full_conc['phone_match'] = full_conc.apply(lambda x: phone_simularity(x.l_phone, x.r_phone), axis=1)\n",
    "    \n",
    "#print(\"phones checked --- %s seconds ---\" % (time.time() - start_time))\n",
    "#print \"\"\n",
    "\n",
    "#test this.  may need to make more efficient but I think it should work\n",
    "start_time = time.time()\n",
    "print \"DISTILLING STRONG ORG DUPLICATES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#calculate composite match score based on component scores and weights\n",
    "full_conc['composite_match_score'] = full_conc.jaro_score * name_weight \\\n",
    "+ full_conc.fuzz_partial_score * name_weight \\\n",
    "+ full_conc.fuzz_sort_score * name_weight \\\n",
    "+ full_conc.fuzz_set_score * name_weight \\\n",
    "+ full_conc.zip_match * zip_weight \\\n",
    "+ full_conc.state_match * state_weight \\\n",
    "#+ full_conc.phone_match * phone_weight\n",
    "\n",
    "org_duplicates = full_conc[full_conc.composite_match_score >= composite_score_min]\n",
    "\n",
    "print(\"final duplicates isolated --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "#full_conc[full_conc.composite_match_score < 3].sort_values(by='composite_match_score', ascending=False)\n",
    "org_duplicates.sort_values(by='composite_match_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_keyed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ebff2d020645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mleft_keyed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'left_keyed' is not defined"
     ]
    }
   ],
   "source": [
    "left_keyed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25699, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of >3.5 dups found with 3 token minimum\n",
    "org_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "org_duplicates.to_csv('salehs file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1062'),\n",
       " ('1053', '1062'),\n",
       " ('1057', '1062'),\n",
       " ('1058', '1062'),\n",
       " ('1059', '1062'),\n",
       " ('1060', '1062'),\n",
       " ('1061', '1062'),\n",
       " ('1064', '1062'),\n",
       " ('1188', '1062'),\n",
       " ('1377', '1062'),\n",
       " ('1831', '1062'),\n",
       " ('213', '1062'),\n",
       " ('2257', '1062'),\n",
       " ('2536', '1062'),\n",
       " ('280', '1062'),\n",
       " ('3108', '1062'),\n",
       " ('3117', '1062'),\n",
       " ('3595', '1062'),\n",
       " ('3738', '1062'),\n",
       " ('3781', '1062'),\n",
       " ('417', '1062'),\n",
       " ('4687', '1062'),\n",
       " ('474', '1062'),\n",
       " ('5081', '1062'),\n",
       " ('518', '1062'),\n",
       " ('5611', '1062'),\n",
       " ('5690', '1062'),\n",
       " ('570', '1062'),\n",
       " ('5726', '1062'),\n",
       " ('6073', '1062'),\n",
       " ('6076', '1062'),\n",
       " ('6247', '1062'),\n",
       " ('6538', '1062'),\n",
       " ('6683', '1062'),\n",
       " ('6686', '1062'),\n",
       " ('688', '1062'),\n",
       " ('7062', '1062'),\n",
       " ('7091', '1062'),\n",
       " ('7202', '1062'),\n",
       " ('7205', '1062'),\n",
       " ('7206', '1062'),\n",
       " ('7207', '1062'),\n",
       " ('7217', '1062'),\n",
       " ('7218', '1062'),\n",
       " ('7220', '1062'),\n",
       " ('7222', '1062'),\n",
       " ('7567', '1062'),\n",
       " ('7756', '1062'),\n",
       " ('7774', '1062'),\n",
       " ('7777', '1062'),\n",
       " ('7782', '1062'),\n",
       " ('7786', '1062'),\n",
       " ('7798', '1062'),\n",
       " ('854', '1062'),\n",
       " ('8750', '1062'),\n",
       " ('8836', '1062'),\n",
       " ('9567', '1062'),\n",
       " ('9578', '1062'),\n",
       " ('963', '1062'),\n",
       " ('9756', '1062'),\n",
       " ('1', '1188'),\n",
       " ('1062', '1188'),\n",
       " ('1101', '1188'),\n",
       " ('1377', '1188'),\n",
       " ('1384', '1188'),\n",
       " ('1652', '1188'),\n",
       " ('1689', '1188'),\n",
       " ('1831', '1188'),\n",
       " ('213', '1188'),\n",
       " ('2257', '1188'),\n",
       " ('2536', '1188'),\n",
       " ('280', '1188'),\n",
       " ('3117', '1188'),\n",
       " ('3146', '1188'),\n",
       " ('3534', '1188'),\n",
       " ('3595', '1188'),\n",
       " ('3781', '1188'),\n",
       " ('417', '1188'),\n",
       " ('448', '1188'),\n",
       " ('4687', '1188'),\n",
       " ('474', '1188'),\n",
       " ('4807', '1188'),\n",
       " ('5081', '1188'),\n",
       " ('515', '1188'),\n",
       " ('518', '1188'),\n",
       " ('540', '1188'),\n",
       " ('5611', '1188'),\n",
       " ('5690', '1188'),\n",
       " ('570', '1188'),\n",
       " ('5726', '1188'),\n",
       " ('6073', '1188'),\n",
       " ('6247', '1188'),\n",
       " ('6538', '1188'),\n",
       " ('6683', '1188'),\n",
       " ('6686', '1188'),\n",
       " ('688', '1188'),\n",
       " ('7062', '1188'),\n",
       " ('7091', '1188'),\n",
       " ('7202', '1188'),\n",
       " ('7205', '1188'),\n",
       " ('7206', '1188'),\n",
       " ('7207', '1188'),\n",
       " ('7217', '1188'),\n",
       " ('7218', '1188'),\n",
       " ('7220', '1188'),\n",
       " ('7222', '1188'),\n",
       " ('7314', '1188'),\n",
       " ('7567', '1188'),\n",
       " ('7756', '1188'),\n",
       " ('7774', '1188'),\n",
       " ('7777', '1188'),\n",
       " ('7782', '1188'),\n",
       " ('7786', '1188'),\n",
       " ('7798', '1188'),\n",
       " ('7948', '1188'),\n",
       " ('8213', '1188'),\n",
       " ('854', '1188'),\n",
       " ('8836', '1188'),\n",
       " ('9269', '1188'),\n",
       " ('9567', '1188'),\n",
       " ('9578', '1188'),\n",
       " ('963', '1188'),\n",
       " ('9756', '1188'),\n",
       " ('9760', '1188'),\n",
       " ('9849', '1188'),\n",
       " ('1', '1377'),\n",
       " ('1062', '1377'),\n",
       " ('1188', '1377'),\n",
       " ('1712', '1377'),\n",
       " ('1831', '1377'),\n",
       " ('213', '1377'),\n",
       " ('2257', '1377'),\n",
       " ('2536', '1377'),\n",
       " ('280', '1377'),\n",
       " ('3117', '1377'),\n",
       " ('3595', '1377'),\n",
       " ('3781', '1377'),\n",
       " ('417', '1377'),\n",
       " ('4687', '1377'),\n",
       " ('474', '1377'),\n",
       " ('5081', '1377'),\n",
       " ('518', '1377'),\n",
       " ('5611', '1377'),\n",
       " ('5690', '1377'),\n",
       " ('570', '1377'),\n",
       " ('5726', '1377'),\n",
       " ('6073', '1377'),\n",
       " ('6247', '1377'),\n",
       " ('6538', '1377'),\n",
       " ('6683', '1377'),\n",
       " ('6686', '1377'),\n",
       " ('688', '1377'),\n",
       " ('7062', '1377'),\n",
       " ('7091', '1377'),\n",
       " ('7202', '1377'),\n",
       " ('7205', '1377'),\n",
       " ('7206', '1377'),\n",
       " ('7207', '1377'),\n",
       " ('7217', '1377'),\n",
       " ('7218', '1377'),\n",
       " ('7220', '1377'),\n",
       " ('7222', '1377'),\n",
       " ('7567', '1377'),\n",
       " ('7756', '1377'),\n",
       " ('7774', '1377'),\n",
       " ('7777', '1377'),\n",
       " ('7782', '1377'),\n",
       " ('7786', '1377'),\n",
       " ('7798', '1377'),\n",
       " ('854', '1377'),\n",
       " ('8836', '1377'),\n",
       " ('9567', '1377'),\n",
       " ('9578', '1377'),\n",
       " ('963', '1377'),\n",
       " ('9756', '1377'),\n",
       " ('1', '1831'),\n",
       " ('1062', '1831'),\n",
       " ('1188', '1831'),\n",
       " ('1377', '1831'),\n",
       " ('213', '1831'),\n",
       " ('2257', '1831'),\n",
       " ('2536', '1831'),\n",
       " ('280', '1831'),\n",
       " ('3117', '1831'),\n",
       " ('3595', '1831'),\n",
       " ('3738', '1831'),\n",
       " ('3781', '1831'),\n",
       " ('417', '1831'),\n",
       " ('4687', '1831'),\n",
       " ('474', '1831'),\n",
       " ('5081', '1831'),\n",
       " ('518', '1831'),\n",
       " ('5611', '1831'),\n",
       " ('5690', '1831'),\n",
       " ('570', '1831'),\n",
       " ('5726', '1831'),\n",
       " ('6073', '1831'),\n",
       " ('6247', '1831'),\n",
       " ('6538', '1831'),\n",
       " ('6683', '1831'),\n",
       " ('6686', '1831'),\n",
       " ('688', '1831'),\n",
       " ('7062', '1831'),\n",
       " ('7091', '1831'),\n",
       " ('7202', '1831'),\n",
       " ('7205', '1831'),\n",
       " ('7206', '1831'),\n",
       " ('7207', '1831'),\n",
       " ('7217', '1831'),\n",
       " ('7218', '1831'),\n",
       " ('7220', '1831'),\n",
       " ('7222', '1831'),\n",
       " ('7416', '1831'),\n",
       " ('7567', '1831'),\n",
       " ('7756', '1831'),\n",
       " ('7774', '1831'),\n",
       " ('7777', '1831'),\n",
       " ('7782', '1831'),\n",
       " ('7786', '1831'),\n",
       " ('7798', '1831'),\n",
       " ('854', '1831'),\n",
       " ('8750', '1831'),\n",
       " ('8836', '1831'),\n",
       " ('9567', '1831'),\n",
       " ('9578', '1831'),\n",
       " ('963', '1831'),\n",
       " ('9756', '1831'),\n",
       " ('1', '213'),\n",
       " ('1062', '213'),\n",
       " ('1188', '213'),\n",
       " ('1377', '213'),\n",
       " ('1831', '213'),\n",
       " ('2257', '213'),\n",
       " ('2536', '213'),\n",
       " ('280', '213'),\n",
       " ('3117', '213'),\n",
       " ('3209', '213'),\n",
       " ('3595', '213'),\n",
       " ('3781', '213'),\n",
       " ('417', '213'),\n",
       " ('4687', '213'),\n",
       " ('474', '213'),\n",
       " ('5081', '213'),\n",
       " ('518', '213'),\n",
       " ('5230', '213'),\n",
       " ('538', '213'),\n",
       " ('5611', '213'),\n",
       " ('5690', '213'),\n",
       " ('570', '213'),\n",
       " ('5726', '213'),\n",
       " ('6073', '213'),\n",
       " ('6247', '213'),\n",
       " ('6538', '213'),\n",
       " ('6683', '213'),\n",
       " ('6686', '213'),\n",
       " ('6711', '213'),\n",
       " ('688', '213'),\n",
       " ('7062', '213'),\n",
       " ('7091', '213'),\n",
       " ('7202', '213'),\n",
       " ('7205', '213'),\n",
       " ('7206', '213'),\n",
       " ('7207', '213'),\n",
       " ('7217', '213'),\n",
       " ('7218', '213'),\n",
       " ('7220', '213'),\n",
       " ('7222', '213'),\n",
       " ('7567', '213'),\n",
       " ('7756', '213'),\n",
       " ('7774', '213'),\n",
       " ('7777', '213'),\n",
       " ('7782', '213'),\n",
       " ('7786', '213'),\n",
       " ('7798', '213'),\n",
       " ('7911', '213'),\n",
       " ('854', '213'),\n",
       " ('8836', '213'),\n",
       " ('9567', '213'),\n",
       " ('9578', '213'),\n",
       " ('963', '213'),\n",
       " ('9756', '213'),\n",
       " ('1', '2257'),\n",
       " ('1062', '2257'),\n",
       " ('1188', '2257'),\n",
       " ('1377', '2257'),\n",
       " ('1831', '2257'),\n",
       " ('213', '2257'),\n",
       " ('2536', '2257'),\n",
       " ('280', '2257'),\n",
       " ('3117', '2257'),\n",
       " ('3595', '2257'),\n",
       " ('3781', '2257'),\n",
       " ('417', '2257'),\n",
       " ('4687', '2257'),\n",
       " ('474', '2257'),\n",
       " ('5081', '2257'),\n",
       " ('518', '2257'),\n",
       " ('5611', '2257'),\n",
       " ('5690', '2257'),\n",
       " ('570', '2257'),\n",
       " ('5726', '2257'),\n",
       " ('6073', '2257'),\n",
       " ('6247', '2257'),\n",
       " ('6538', '2257'),\n",
       " ('6683', '2257'),\n",
       " ('6686', '2257'),\n",
       " ('688', '2257'),\n",
       " ('7062', '2257'),\n",
       " ('7091', '2257'),\n",
       " ('7202', '2257'),\n",
       " ('7205', '2257'),\n",
       " ('7206', '2257'),\n",
       " ('7207', '2257'),\n",
       " ('7217', '2257'),\n",
       " ('7218', '2257'),\n",
       " ('7220', '2257'),\n",
       " ('7222', '2257'),\n",
       " ('7567', '2257'),\n",
       " ('7756', '2257'),\n",
       " ('7774', '2257'),\n",
       " ('7777', '2257'),\n",
       " ('7782', '2257'),\n",
       " ('7786', '2257'),\n",
       " ('7798', '2257'),\n",
       " ('854', '2257'),\n",
       " ('8836', '2257'),\n",
       " ('9567', '2257'),\n",
       " ('9578', '2257'),\n",
       " ('963', '2257'),\n",
       " ('9756', '2257'),\n",
       " ('1', '2536'),\n",
       " ('1062', '2536'),\n",
       " ('1152', '2536'),\n",
       " ('1188', '2536'),\n",
       " ('1265', '2536'),\n",
       " ('1286', '2536'),\n",
       " ('1355', '2536'),\n",
       " ('1377', '2536'),\n",
       " ('1419', '2536'),\n",
       " ('1456', '2536'),\n",
       " ('1715', '2536'),\n",
       " ('1789', '2536'),\n",
       " ('1831', '2536'),\n",
       " ('1988', '2536'),\n",
       " ('210', '2536'),\n",
       " ('211', '2536'),\n",
       " ('213', '2536'),\n",
       " ('2134', '2536'),\n",
       " ('2163', '2536'),\n",
       " ('2169', '2536'),\n",
       " ('2220', '2536'),\n",
       " ('2240', '2536'),\n",
       " ('2257', '2536'),\n",
       " ('2263', '2536'),\n",
       " ('2280', '2536'),\n",
       " ('2400', '2536'),\n",
       " ('2408', '2536'),\n",
       " ('2415', '2536'),\n",
       " ('242', '2536'),\n",
       " ('246', '2536'),\n",
       " ('2526', '2536'),\n",
       " ('2723', '2536'),\n",
       " ('2731', '2536'),\n",
       " ('2732', '2536'),\n",
       " ('2769', '2536'),\n",
       " ('280', '2536'),\n",
       " ('2857', '2536'),\n",
       " ('2874', '2536'),\n",
       " ('2881', '2536'),\n",
       " ('2975', '2536'),\n",
       " ('3010', '2536'),\n",
       " ('3041', '2536'),\n",
       " ('3044', '2536'),\n",
       " ('3064', '2536'),\n",
       " ('3108', '2536'),\n",
       " ('3117', '2536'),\n",
       " ('3346', '2536'),\n",
       " ('341', '2536'),\n",
       " ('3438', '2536'),\n",
       " ('3486', '2536'),\n",
       " ('3534', '2536'),\n",
       " ('3595', '2536'),\n",
       " ('362', '2536'),\n",
       " ('3624', '2536'),\n",
       " ('3738', '2536'),\n",
       " ('3741', '2536'),\n",
       " ('376', '2536'),\n",
       " ('3774', '2536'),\n",
       " ('3775', '2536'),\n",
       " ('3776', '2536'),\n",
       " ('3781', '2536'),\n",
       " ('386', '2536'),\n",
       " ('387', '2536'),\n",
       " ('390', '2536'),\n",
       " ('3940', '2536'),\n",
       " ('406', '2536'),\n",
       " ('4103', '2536'),\n",
       " ('417', '2536'),\n",
       " ('4299', '2536'),\n",
       " ('4385', '2536'),\n",
       " ('4437', '2536'),\n",
       " ('4618', '2536'),\n",
       " ('4646', '2536'),\n",
       " ('4664', '2536'),\n",
       " ('4683', '2536'),\n",
       " ('4687', '2536'),\n",
       " ('474', '2536'),\n",
       " ('4743', '2536'),\n",
       " ('4893', '2536'),\n",
       " ('4926', '2536'),\n",
       " ('5040', '2536'),\n",
       " ('5074', '2536'),\n",
       " ('5081', '2536'),\n",
       " ('5085', '2536'),\n",
       " ('5086', '2536'),\n",
       " ('518', '2536'),\n",
       " ('5196', '2536'),\n",
       " ('5210', '2536'),\n",
       " ('5444', '2536'),\n",
       " ('5499', '2536'),\n",
       " ('5555', '2536'),\n",
       " ('5608', '2536'),\n",
       " ('5611', '2536'),\n",
       " ('5690', '2536'),\n",
       " ('570', '2536'),\n",
       " ('5726', '2536'),\n",
       " ('5744', '2536'),\n",
       " ('6073', '2536'),\n",
       " ('6074', '2536'),\n",
       " ('6075', '2536'),\n",
       " ('6076', '2536'),\n",
       " ('615', '2536'),\n",
       " ('62', '2536'),\n",
       " ('6211', '2536'),\n",
       " ('6247', '2536'),\n",
       " ('6333', '2536'),\n",
       " ('643', '2536'),\n",
       " ('645', '2536'),\n",
       " ('6538', '2536'),\n",
       " ('6572', '2536'),\n",
       " ('6618', '2536'),\n",
       " ('6683', '2536'),\n",
       " ('6686', '2536'),\n",
       " ('6691', '2536'),\n",
       " ('6713', '2536'),\n",
       " ('6798', '2536'),\n",
       " ('6848', '2536'),\n",
       " ('6858', '2536'),\n",
       " ('688', '2536'),\n",
       " ('6905', '2536'),\n",
       " ('6926', '2536'),\n",
       " ('6928', '2536'),\n",
       " ('6933', '2536'),\n",
       " ('6935', '2536'),\n",
       " ('6936', '2536'),\n",
       " ('6938', '2536'),\n",
       " ('6942', '2536'),\n",
       " ('7005', '2536'),\n",
       " ('7062', '2536'),\n",
       " ('7064', '2536'),\n",
       " ('7086', '2536'),\n",
       " ('709', '2536'),\n",
       " ('7090', '2536'),\n",
       " ('7091', '2536'),\n",
       " ('7200', '2536'),\n",
       " ('7202', '2536'),\n",
       " ('7205', '2536'),\n",
       " ('7206', '2536'),\n",
       " ('7207', '2536'),\n",
       " ('7208', '2536'),\n",
       " ('7215', '2536'),\n",
       " ('7216', '2536'),\n",
       " ('7217', '2536'),\n",
       " ('7218', '2536'),\n",
       " ('7220', '2536'),\n",
       " ('7222', '2536'),\n",
       " ('7247', '2536'),\n",
       " ('7258', '2536'),\n",
       " ('728', '2536'),\n",
       " ('7316', '2536'),\n",
       " ('7327', '2536'),\n",
       " ('7403', '2536'),\n",
       " ('744', '2536'),\n",
       " ('7516', '2536'),\n",
       " ('7519', '2536'),\n",
       " ('7567', '2536'),\n",
       " ('7756', '2536'),\n",
       " ('7767', '2536'),\n",
       " ('7768', '2536'),\n",
       " ('7769', '2536'),\n",
       " ('7770', '2536'),\n",
       " ('7771', '2536'),\n",
       " ('7773', '2536'),\n",
       " ('7774', '2536'),\n",
       " ('7775', '2536'),\n",
       " ('7776', '2536'),\n",
       " ('7777', '2536'),\n",
       " ('7782', '2536'),\n",
       " ('7783', '2536'),\n",
       " ('7786', '2536'),\n",
       " ('7788', '2536'),\n",
       " ('7789', '2536'),\n",
       " ('7791', '2536'),\n",
       " ('7792', '2536'),\n",
       " ('7793', '2536'),\n",
       " ('7797', '2536'),\n",
       " ('7798', '2536'),\n",
       " ('7799', '2536'),\n",
       " ('7801', '2536'),\n",
       " ('7852', '2536'),\n",
       " ('7974', '2536'),\n",
       " ('7985', '2536'),\n",
       " ('7993', '2536'),\n",
       " ('8255', '2536'),\n",
       " ('8342', '2536'),\n",
       " ('8427', '2536'),\n",
       " ('8457', '2536'),\n",
       " ('854', '2536'),\n",
       " ('8576', '2536'),\n",
       " ('8609', '2536'),\n",
       " ('8639', '2536'),\n",
       " ('8658', '2536'),\n",
       " ('8669', '2536'),\n",
       " ('8699', '2536'),\n",
       " ('8714', '2536'),\n",
       " ('8745', '2536'),\n",
       " ('8746', '2536'),\n",
       " ('8749', '2536'),\n",
       " ('8750', '2536'),\n",
       " ('8836', '2536'),\n",
       " ('8885', '2536'),\n",
       " ('8912', '2536'),\n",
       " ('8927', '2536'),\n",
       " ('9066', '2536'),\n",
       " ('9082', '2536'),\n",
       " ('9197', '2536'),\n",
       " ('9277', '2536'),\n",
       " ('9315', '2536'),\n",
       " ('9336', '2536'),\n",
       " ('9375', '2536'),\n",
       " ('9428', '2536'),\n",
       " ('9452', '2536'),\n",
       " ('9467', '2536'),\n",
       " ('9499', '2536'),\n",
       " ('9567', '2536'),\n",
       " ('9578', '2536'),\n",
       " ('960', '2536'),\n",
       " ('963', '2536'),\n",
       " ('9641', '2536'),\n",
       " ('9699', '2536'),\n",
       " ('9726', '2536'),\n",
       " ('9750', '2536'),\n",
       " ('9756', '2536'),\n",
       " ('9779', '2536'),\n",
       " ('9961', '2536'),\n",
       " ('9974', '2536'),\n",
       " ('9993', '2536'),\n",
       " ('1', '280'),\n",
       " ('1062', '280'),\n",
       " ('1188', '280'),\n",
       " ('1377', '280'),\n",
       " ('1831', '280'),\n",
       " ('213', '280'),\n",
       " ('2257', '280'),\n",
       " ('2536', '280'),\n",
       " ('3117', '280'),\n",
       " ('3595', '280'),\n",
       " ('3781', '280'),\n",
       " ('417', '280'),\n",
       " ('4687', '280'),\n",
       " ('474', '280'),\n",
       " ('5081', '280'),\n",
       " ('518', '280'),\n",
       " ('5611', '280'),\n",
       " ('5690', '280'),\n",
       " ('570', '280'),\n",
       " ('5726', '280'),\n",
       " ('6073', '280'),\n",
       " ('6247', '280'),\n",
       " ('6538', '280'),\n",
       " ('6683', '280'),\n",
       " ('6686', '280'),\n",
       " ('688', '280'),\n",
       " ('7062', '280'),\n",
       " ('7091', '280'),\n",
       " ('7202', '280'),\n",
       " ('7205', '280'),\n",
       " ('7206', '280'),\n",
       " ('7207', '280'),\n",
       " ('7217', '280'),\n",
       " ('7218', '280'),\n",
       " ('7220', '280'),\n",
       " ('7222', '280'),\n",
       " ('7567', '280'),\n",
       " ('7756', '280'),\n",
       " ('7774', '280'),\n",
       " ('7777', '280'),\n",
       " ('7782', '280'),\n",
       " ('7786', '280'),\n",
       " ('7798', '280'),\n",
       " ('854', '280'),\n",
       " ('8836', '280'),\n",
       " ('9567', '280'),\n",
       " ('9578', '280'),\n",
       " ('963', '280'),\n",
       " ('9756', '280'),\n",
       " ('1', '3117'),\n",
       " ('1062', '3117'),\n",
       " ('1188', '3117'),\n",
       " ('1377', '3117'),\n",
       " ('1831', '3117'),\n",
       " ('213', '3117'),\n",
       " ('2257', '3117'),\n",
       " ('2536', '3117'),\n",
       " ('280', '3117'),\n",
       " ('3015', '3117'),\n",
       " ('3595', '3117'),\n",
       " ('3781', '3117'),\n",
       " ('417', '3117'),\n",
       " ('4687', '3117'),\n",
       " ('474', '3117'),\n",
       " ('5081', '3117'),\n",
       " ('518', '3117'),\n",
       " ('5611', '3117'),\n",
       " ('5690', '3117'),\n",
       " ('570', '3117'),\n",
       " ('5726', '3117'),\n",
       " ('6073', '3117'),\n",
       " ('6247', '3117'),\n",
       " ('6538', '3117'),\n",
       " ('6683', '3117'),\n",
       " ('6686', '3117'),\n",
       " ('688', '3117'),\n",
       " ('7062', '3117'),\n",
       " ('7091', '3117'),\n",
       " ('7202', '3117'),\n",
       " ('7205', '3117'),\n",
       " ('7206', '3117'),\n",
       " ('7207', '3117'),\n",
       " ('7217', '3117'),\n",
       " ('7218', '3117'),\n",
       " ('7220', '3117'),\n",
       " ('7222', '3117'),\n",
       " ('7567', '3117'),\n",
       " ('7756', '3117'),\n",
       " ('7774', '3117'),\n",
       " ('7777', '3117'),\n",
       " ('7782', '3117'),\n",
       " ('7786', '3117'),\n",
       " ('7798', '3117'),\n",
       " ('854', '3117'),\n",
       " ('8836', '3117'),\n",
       " ('9567', '3117'),\n",
       " ('9578', '3117'),\n",
       " ('963', '3117'),\n",
       " ('9756', '3117'),\n",
       " ('1', '3595'),\n",
       " ('1062', '3595'),\n",
       " ('1188', '3595'),\n",
       " ('1377', '3595'),\n",
       " ('1831', '3595'),\n",
       " ('213', '3595'),\n",
       " ('2257', '3595'),\n",
       " ('2536', '3595'),\n",
       " ('280', '3595'),\n",
       " ('3117', '3595'),\n",
       " ('3781', '3595'),\n",
       " ('417', '3595'),\n",
       " ('4687', '3595'),\n",
       " ('474', '3595'),\n",
       " ('5081', '3595'),\n",
       " ('518', '3595'),\n",
       " ('5611', '3595'),\n",
       " ('5690', '3595'),\n",
       " ('570', '3595'),\n",
       " ('5726', '3595'),\n",
       " ('6073', '3595'),\n",
       " ('6247', '3595'),\n",
       " ('6538', '3595'),\n",
       " ('6683', '3595'),\n",
       " ('6686', '3595'),\n",
       " ('688', '3595'),\n",
       " ('7062', '3595'),\n",
       " ('7091', '3595'),\n",
       " ('7202', '3595'),\n",
       " ('7205', '3595'),\n",
       " ('7206', '3595'),\n",
       " ('7207', '3595'),\n",
       " ('7217', '3595'),\n",
       " ('7218', '3595'),\n",
       " ('7220', '3595'),\n",
       " ('7222', '3595'),\n",
       " ('7567', '3595'),\n",
       " ('7756', '3595'),\n",
       " ('7774', '3595'),\n",
       " ('7777', '3595'),\n",
       " ('7782', '3595'),\n",
       " ('7786', '3595'),\n",
       " ('7798', '3595'),\n",
       " ('854', '3595'),\n",
       " ('8836', '3595'),\n",
       " ('9567', '3595'),\n",
       " ('9578', '3595'),\n",
       " ('963', '3595'),\n",
       " ('9756', '3595'),\n",
       " ('1', '3781'),\n",
       " ('1062', '3781'),\n",
       " ('1188', '3781'),\n",
       " ('1377', '3781'),\n",
       " ('1831', '3781'),\n",
       " ('213', '3781'),\n",
       " ('2257', '3781'),\n",
       " ('2536', '3781'),\n",
       " ('280', '3781'),\n",
       " ('2821', '3781'),\n",
       " ('3117', '3781'),\n",
       " ('3595', '3781'),\n",
       " ('417', '3781'),\n",
       " ('4687', '3781'),\n",
       " ('474', '3781'),\n",
       " ('5081', '3781'),\n",
       " ('518', '3781'),\n",
       " ('5611', '3781'),\n",
       " ('5690', '3781'),\n",
       " ('570', '3781'),\n",
       " ('5726', '3781'),\n",
       " ('6073', '3781'),\n",
       " ('6247', '3781'),\n",
       " ('6538', '3781'),\n",
       " ('6683', '3781'),\n",
       " ('6686', '3781'),\n",
       " ('688', '3781'),\n",
       " ('7062', '3781'),\n",
       " ('7091', '3781'),\n",
       " ('7202', '3781'),\n",
       " ('7205', '3781'),\n",
       " ('7206', '3781'),\n",
       " ('7207', '3781'),\n",
       " ('7217', '3781'),\n",
       " ('7218', '3781'),\n",
       " ('7220', '3781'),\n",
       " ('7222', '3781'),\n",
       " ('7567', '3781'),\n",
       " ('7756', '3781'),\n",
       " ('7774', '3781'),\n",
       " ('7777', '3781'),\n",
       " ('7782', '3781'),\n",
       " ('7786', '3781'),\n",
       " ('7798', '3781'),\n",
       " ('854', '3781'),\n",
       " ('8836', '3781'),\n",
       " ('9567', '3781'),\n",
       " ('9578', '3781'),\n",
       " ('963', '3781'),\n",
       " ('9756', '3781'),\n",
       " ('1', '417'),\n",
       " ('1062', '417'),\n",
       " ('1188', '417'),\n",
       " ('1377', '417'),\n",
       " ('1831', '417'),\n",
       " ('213', '417'),\n",
       " ('2257', '417'),\n",
       " ('2536', '417'),\n",
       " ('280', '417'),\n",
       " ('3117', '417'),\n",
       " ('3595', '417'),\n",
       " ('3781', '417'),\n",
       " ('4687', '417'),\n",
       " ('474', '417'),\n",
       " ('5081', '417'),\n",
       " ('518', '417'),\n",
       " ('5611', '417'),\n",
       " ('5690', '417'),\n",
       " ('570', '417'),\n",
       " ('5726', '417'),\n",
       " ('6073', '417'),\n",
       " ('6247', '417'),\n",
       " ('6538', '417'),\n",
       " ('6683', '417'),\n",
       " ('6686', '417'),\n",
       " ('688', '417'),\n",
       " ('7062', '417'),\n",
       " ('7091', '417'),\n",
       " ('7202', '417'),\n",
       " ('7205', '417'),\n",
       " ('7206', '417'),\n",
       " ('7207', '417'),\n",
       " ('7217', '417'),\n",
       " ('7218', '417'),\n",
       " ('7220', '417'),\n",
       " ('7222', '417'),\n",
       " ('7567', '417'),\n",
       " ('7756', '417'),\n",
       " ('7774', '417'),\n",
       " ('7777', '417'),\n",
       " ('7782', '417'),\n",
       " ('7786', '417'),\n",
       " ('7798', '417'),\n",
       " ('854', '417'),\n",
       " ('8836', '417'),\n",
       " ('9567', '417'),\n",
       " ('9578', '417'),\n",
       " ('963', '417'),\n",
       " ('9756', '417'),\n",
       " ('1', '4687'),\n",
       " ('1062', '4687'),\n",
       " ('1188', '4687'),\n",
       " ('1377', '4687'),\n",
       " ('1831', '4687'),\n",
       " ('213', '4687'),\n",
       " ('2257', '4687'),\n",
       " ('2536', '4687'),\n",
       " ('280', '4687'),\n",
       " ('3117', '4687'),\n",
       " ('3595', '4687'),\n",
       " ('3781', '4687'),\n",
       " ('417', '4687'),\n",
       " ('474', '4687'),\n",
       " ('5081', '4687'),\n",
       " ('518', '4687'),\n",
       " ('5611', '4687'),\n",
       " ('5690', '4687'),\n",
       " ('570', '4687'),\n",
       " ('5726', '4687'),\n",
       " ('6073', '4687'),\n",
       " ('6247', '4687'),\n",
       " ('6538', '4687'),\n",
       " ('6683', '4687'),\n",
       " ('6686', '4687'),\n",
       " ('688', '4687'),\n",
       " ('7062', '4687'),\n",
       " ('7091', '4687'),\n",
       " ('7202', '4687'),\n",
       " ('7205', '4687'),\n",
       " ('7206', '4687'),\n",
       " ('7207', '4687'),\n",
       " ('7217', '4687'),\n",
       " ('7218', '4687'),\n",
       " ('7220', '4687'),\n",
       " ('7222', '4687'),\n",
       " ('7567', '4687'),\n",
       " ('7756', '4687'),\n",
       " ('7774', '4687'),\n",
       " ('7777', '4687'),\n",
       " ('7782', '4687'),\n",
       " ('7786', '4687'),\n",
       " ('7798', '4687'),\n",
       " ('854', '4687'),\n",
       " ('8836', '4687'),\n",
       " ('9567', '4687'),\n",
       " ('9578', '4687'),\n",
       " ('963', '4687'),\n",
       " ('9756', '4687'),\n",
       " ('1', '474'),\n",
       " ('1062', '474'),\n",
       " ('1188', '474'),\n",
       " ('1377', '474'),\n",
       " ('1712', '474'),\n",
       " ('1831', '474'),\n",
       " ('213', '474'),\n",
       " ('2257', '474'),\n",
       " ('2536', '474'),\n",
       " ('280', '474'),\n",
       " ('3117', '474'),\n",
       " ('3595', '474'),\n",
       " ('3781', '474'),\n",
       " ('414', '474'),\n",
       " ('417', '474'),\n",
       " ('4687', '474'),\n",
       " ('5081', '474'),\n",
       " ('518', '474'),\n",
       " ('5611', '474'),\n",
       " ('5690', '474'),\n",
       " ('570', '474'),\n",
       " ('5726', '474'),\n",
       " ('6073', '474'),\n",
       " ('6247', '474'),\n",
       " ('6538', '474'),\n",
       " ('6683', '474'),\n",
       " ('6686', '474'),\n",
       " ('688', '474'),\n",
       " ('7062', '474'),\n",
       " ('7091', '474'),\n",
       " ('7202', '474'),\n",
       " ('7205', '474'),\n",
       " ('7206', '474'),\n",
       " ('7207', '474'),\n",
       " ('7217', '474'),\n",
       " ('7218', '474'),\n",
       " ('7220', '474'),\n",
       " ('7222', '474'),\n",
       " ('7567', '474'),\n",
       " ('7756', '474'),\n",
       " ('7774', '474'),\n",
       " ('7777', '474'),\n",
       " ('7782', '474'),\n",
       " ('7786', '474'),\n",
       " ('7798', '474'),\n",
       " ('854', '474'),\n",
       " ('8836', '474'),\n",
       " ('8940', '474'),\n",
       " ('9567', '474'),\n",
       " ('9578', '474'),\n",
       " ('963', '474'),\n",
       " ('9756', '474'),\n",
       " ('1', '5081'),\n",
       " ('1062', '5081'),\n",
       " ('1188', '5081'),\n",
       " ('1377', '5081'),\n",
       " ('1831', '5081'),\n",
       " ('213', '5081'),\n",
       " ('2257', '5081'),\n",
       " ('2536', '5081'),\n",
       " ('280', '5081'),\n",
       " ('3117', '5081'),\n",
       " ('3595', '5081'),\n",
       " ('3781', '5081'),\n",
       " ('417', '5081'),\n",
       " ('4687', '5081'),\n",
       " ('474', '5081'),\n",
       " ('518', '5081'),\n",
       " ('5611', '5081'),\n",
       " ('5690', '5081'),\n",
       " ('570', '5081'),\n",
       " ('5726', '5081'),\n",
       " ('6073', '5081'),\n",
       " ('6247', '5081'),\n",
       " ('6538', '5081'),\n",
       " ('6683', '5081'),\n",
       " ('6686', '5081'),\n",
       " ('688', '5081'),\n",
       " ('7062', '5081'),\n",
       " ('7091', '5081'),\n",
       " ('7202', '5081'),\n",
       " ('7205', '5081'),\n",
       " ('7206', '5081'),\n",
       " ('7207', '5081'),\n",
       " ('7217', '5081'),\n",
       " ('7218', '5081'),\n",
       " ('7220', '5081'),\n",
       " ('7222', '5081'),\n",
       " ('7567', '5081'),\n",
       " ('7756', '5081'),\n",
       " ('7774', '5081'),\n",
       " ('7777', '5081'),\n",
       " ('7782', '5081'),\n",
       " ('7786', '5081'),\n",
       " ('7798', '5081'),\n",
       " ('854', '5081'),\n",
       " ('8836', '5081'),\n",
       " ('9567', '5081'),\n",
       " ('9578', '5081'),\n",
       " ('963', '5081'),\n",
       " ('9756', '5081'),\n",
       " ('1', '518'),\n",
       " ('1062', '518'),\n",
       " ('1188', '518'),\n",
       " ('1377', '518'),\n",
       " ('1831', '518'),\n",
       " ('213', '518'),\n",
       " ('2257', '518'),\n",
       " ('2536', '518'),\n",
       " ('280', '518'),\n",
       " ('3117', '518'),\n",
       " ('3595', '518'),\n",
       " ('3781', '518'),\n",
       " ('417', '518'),\n",
       " ('4687', '518'),\n",
       " ('474', '518'),\n",
       " ('5081', '518'),\n",
       " ('5611', '518'),\n",
       " ('5690', '518'),\n",
       " ('570', '518'),\n",
       " ('5726', '518'),\n",
       " ('6073', '518'),\n",
       " ('6247', '518'),\n",
       " ('6538', '518'),\n",
       " ('6683', '518'),\n",
       " ('6686', '518'),\n",
       " ('688', '518'),\n",
       " ('7062', '518'),\n",
       " ('7091', '518'),\n",
       " ('7202', '518'),\n",
       " ('7205', '518'),\n",
       " ('7206', '518'),\n",
       " ('7207', '518'),\n",
       " ('7217', '518'),\n",
       " ('7218', '518'),\n",
       " ('7220', '518'),\n",
       " ('7222', '518'),\n",
       " ('7567', '518'),\n",
       " ('7756', '518'),\n",
       " ('7774', '518'),\n",
       " ('7777', '518'),\n",
       " ('7782', '518'),\n",
       " ('7786', '518'),\n",
       " ('7798', '518'),\n",
       " ('854', '518'),\n",
       " ('8836', '518'),\n",
       " ('9567', '518'),\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578412"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4292670, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392645</th>\n",
       "      <td>237891</td>\n",
       "      <td>237867</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392646</th>\n",
       "      <td>237891</td>\n",
       "      <td>237876</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392647</th>\n",
       "      <td>237891</td>\n",
       "      <td>237886</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392648</th>\n",
       "      <td>237891</td>\n",
       "      <td>237888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392649</th>\n",
       "      <td>237891</td>\n",
       "      <td>237890</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_l    id_r  id_l count\n",
       "392645  237891  237867           2\n",
       "392646  237891  237876           2\n",
       "392647  237891  237886           2\n",
       "392648  237891  237888           2\n",
       "392649  237891  237890           2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_dfs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_dfs = pd.concat(dfs_list)\n",
    "\n",
    "match_tuples = list(zip(dup_dfs['id_l'], dup_dfs['id_r']))\n",
    "\n",
    "sorted_match_tuples = []\n",
    "for tup in match_tuples:\n",
    "    s = tuple(sorted(tup))\n",
    "    sorted_match_tuples.append(s)\n",
    "\n",
    "dup_dfs.drop(['id_l','id_r'],axis=1,inplace=True)\n",
    "dup_dfs['id_tuples'] = sorted_match_tuples\n",
    "\n",
    "new_col_list = ['id_l','id_r']\n",
    "for n,col in enumerate(new_col_list):\n",
    "    dup_dfs[col] = dup_dfs['id_tuples'].apply(lambda location: location[n])\n",
    "    \n",
    "dup_dfs.drop('id_tuples',axis=1,inplace=True)\n",
    "dup_dfs.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4292670"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_match_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146335, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_dfs.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "      <th>(id_l_new, id_r_new)</th>\n",
       "      <th>id tuples</th>\n",
       "      <th>id_l_new</th>\n",
       "      <th>id_r_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1004</td>\n",
       "      <td>1003</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1003, 1004)</td>\n",
       "      <td>1003</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1007</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1006, 1007)</td>\n",
       "      <td>1006</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1008</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1006, 1008)</td>\n",
       "      <td>1006</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1008</td>\n",
       "      <td>1007</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1007, 1008)</td>\n",
       "      <td>1007</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1009</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1006, 1009)</td>\n",
       "      <td>1006</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1009</td>\n",
       "      <td>1007</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1007, 1009)</td>\n",
       "      <td>1007</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1009</td>\n",
       "      <td>1008</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1008, 1009)</td>\n",
       "      <td>1008</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1010</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1006, 1010)</td>\n",
       "      <td>1006</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1010</td>\n",
       "      <td>1007</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1007, 1010)</td>\n",
       "      <td>1007</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1010</td>\n",
       "      <td>1008</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1008, 1010)</td>\n",
       "      <td>1008</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1010</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1009, 1010)</td>\n",
       "      <td>1009</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1011</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1006, 1011)</td>\n",
       "      <td>1006</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1011</td>\n",
       "      <td>1007</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1007, 1011)</td>\n",
       "      <td>1007</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1011</td>\n",
       "      <td>1008</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1008, 1011)</td>\n",
       "      <td>1008</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1011</td>\n",
       "      <td>1009</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1009, 1011)</td>\n",
       "      <td>1009</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1011</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1010, 1011)</td>\n",
       "      <td>1010</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1012</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1009, 1012)</td>\n",
       "      <td>1009</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1011, 1012)</td>\n",
       "      <td>1011</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1016</td>\n",
       "      <td>1015</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1015, 1016)</td>\n",
       "      <td>1015</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>1022</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(10, 1022)</td>\n",
       "      <td>10</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1023</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1009, 1023)</td>\n",
       "      <td>1009</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1023</td>\n",
       "      <td>1011</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1011, 1023)</td>\n",
       "      <td>1011</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1023</td>\n",
       "      <td>1012</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1012, 1023)</td>\n",
       "      <td>1012</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1029</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1000, 1029)</td>\n",
       "      <td>1000</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1029</td>\n",
       "      <td>1028</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1028, 1029)</td>\n",
       "      <td>1028</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1030</td>\n",
       "      <td>1029</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1029, 1030)</td>\n",
       "      <td>1029</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>1031</td>\n",
       "      <td>1029</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1029, 1031)</td>\n",
       "      <td>1029</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1032</td>\n",
       "      <td>1029</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1029, 1032)</td>\n",
       "      <td>1029</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1033</td>\n",
       "      <td>1029</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1029, 1033)</td>\n",
       "      <td>1029</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1033</td>\n",
       "      <td>1030</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(1030, 1033)</td>\n",
       "      <td>1030</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392620</th>\n",
       "      <td>237891</td>\n",
       "      <td>237695</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237695, 237891)</td>\n",
       "      <td>237695</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392621</th>\n",
       "      <td>237891</td>\n",
       "      <td>237718</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237718, 237891)</td>\n",
       "      <td>237718</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392622</th>\n",
       "      <td>237891</td>\n",
       "      <td>237720</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237720, 237891)</td>\n",
       "      <td>237720</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392623</th>\n",
       "      <td>237891</td>\n",
       "      <td>237722</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237722, 237891)</td>\n",
       "      <td>237722</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392624</th>\n",
       "      <td>237891</td>\n",
       "      <td>237734</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237734, 237891)</td>\n",
       "      <td>237734</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392625</th>\n",
       "      <td>237891</td>\n",
       "      <td>237737</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237737, 237891)</td>\n",
       "      <td>237737</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392626</th>\n",
       "      <td>237891</td>\n",
       "      <td>237741</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237741, 237891)</td>\n",
       "      <td>237741</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392627</th>\n",
       "      <td>237891</td>\n",
       "      <td>237742</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237742, 237891)</td>\n",
       "      <td>237742</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392628</th>\n",
       "      <td>237891</td>\n",
       "      <td>237745</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237745, 237891)</td>\n",
       "      <td>237745</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392629</th>\n",
       "      <td>237891</td>\n",
       "      <td>237750</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237750, 237891)</td>\n",
       "      <td>237750</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392630</th>\n",
       "      <td>237891</td>\n",
       "      <td>237751</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237751, 237891)</td>\n",
       "      <td>237751</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392631</th>\n",
       "      <td>237891</td>\n",
       "      <td>237754</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237754, 237891)</td>\n",
       "      <td>237754</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392632</th>\n",
       "      <td>237891</td>\n",
       "      <td>237763</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237763, 237891)</td>\n",
       "      <td>237763</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392633</th>\n",
       "      <td>237891</td>\n",
       "      <td>237772</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237772, 237891)</td>\n",
       "      <td>237772</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392634</th>\n",
       "      <td>237891</td>\n",
       "      <td>237781</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237781, 237891)</td>\n",
       "      <td>237781</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392635</th>\n",
       "      <td>237891</td>\n",
       "      <td>237802</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237802, 237891)</td>\n",
       "      <td>237802</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392636</th>\n",
       "      <td>237891</td>\n",
       "      <td>237807</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237807, 237891)</td>\n",
       "      <td>237807</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392637</th>\n",
       "      <td>237891</td>\n",
       "      <td>237811</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237811, 237891)</td>\n",
       "      <td>237811</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392638</th>\n",
       "      <td>237891</td>\n",
       "      <td>237817</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237817, 237891)</td>\n",
       "      <td>237817</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392639</th>\n",
       "      <td>237891</td>\n",
       "      <td>237822</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237822, 237891)</td>\n",
       "      <td>237822</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392640</th>\n",
       "      <td>237891</td>\n",
       "      <td>237828</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237828, 237891)</td>\n",
       "      <td>237828</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392641</th>\n",
       "      <td>237891</td>\n",
       "      <td>237830</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237830, 237891)</td>\n",
       "      <td>237830</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392642</th>\n",
       "      <td>237891</td>\n",
       "      <td>237840</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237840, 237891)</td>\n",
       "      <td>237840</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392643</th>\n",
       "      <td>237891</td>\n",
       "      <td>237859</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237859, 237891)</td>\n",
       "      <td>237859</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392644</th>\n",
       "      <td>237891</td>\n",
       "      <td>237862</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237862, 237891)</td>\n",
       "      <td>237862</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392645</th>\n",
       "      <td>237891</td>\n",
       "      <td>237867</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237867, 237891)</td>\n",
       "      <td>237867</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392646</th>\n",
       "      <td>237891</td>\n",
       "      <td>237876</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237876, 237891)</td>\n",
       "      <td>237876</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392647</th>\n",
       "      <td>237891</td>\n",
       "      <td>237886</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237886, 237891)</td>\n",
       "      <td>237886</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392648</th>\n",
       "      <td>237891</td>\n",
       "      <td>237888</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237888, 237891)</td>\n",
       "      <td>237888</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392649</th>\n",
       "      <td>237891</td>\n",
       "      <td>237890</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;enumerate object at 0x00000000D8258BD0&gt;</td>\n",
       "      <td>(237890, 237891)</td>\n",
       "      <td>237890</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2146335 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_l    id_r  id_l count                      (id_l_new, id_r_new)  \\\n",
       "171       1004    1003           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "229       1007    1006           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "245       1008    1006           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "246       1008    1007           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "263       1009    1006           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "264       1009    1007           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "265       1009    1008           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "318       1010    1006           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "319       1010    1007           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "320       1010    1008           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "321       1010    1009           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "332       1011    1006           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "333       1011    1007           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "334       1011    1008           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "335       1011    1009           3  <enumerate object at 0x00000000D8258BD0>   \n",
       "336       1011    1010           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "385       1012    1009           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "386       1012    1011           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "472       1016    1015           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "552       1022      10           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "574       1023    1009           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "575       1023    1011           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "576       1023    1012           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "699       1029    1000           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "700       1029    1028           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "750       1030    1029           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "777       1031    1029           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "788       1032    1029           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "796       1033    1029           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "797       1033    1030           3  <enumerate object at 0x00000000D8258BD0>   \n",
       "...        ...     ...         ...                                       ...   \n",
       "392620  237891  237695           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392621  237891  237718           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392622  237891  237720           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392623  237891  237722           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392624  237891  237734           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392625  237891  237737           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392626  237891  237741           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392627  237891  237742           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392628  237891  237745           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392629  237891  237750           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392630  237891  237751           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392631  237891  237754           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392632  237891  237763           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392633  237891  237772           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392634  237891  237781           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392635  237891  237802           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392636  237891  237807           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392637  237891  237811           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392638  237891  237817           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392639  237891  237822           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392640  237891  237828           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392641  237891  237830           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392642  237891  237840           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392643  237891  237859           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392644  237891  237862           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392645  237891  237867           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392646  237891  237876           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392647  237891  237886           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392648  237891  237888           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "392649  237891  237890           2  <enumerate object at 0x00000000D8258BD0>   \n",
       "\n",
       "               id tuples id_l_new id_r_new  \n",
       "171         (1003, 1004)     1003     1004  \n",
       "229         (1006, 1007)     1006     1007  \n",
       "245         (1006, 1008)     1006     1008  \n",
       "246         (1007, 1008)     1007     1008  \n",
       "263         (1006, 1009)     1006     1009  \n",
       "264         (1007, 1009)     1007     1009  \n",
       "265         (1008, 1009)     1008     1009  \n",
       "318         (1006, 1010)     1006     1010  \n",
       "319         (1007, 1010)     1007     1010  \n",
       "320         (1008, 1010)     1008     1010  \n",
       "321         (1009, 1010)     1009     1010  \n",
       "332         (1006, 1011)     1006     1011  \n",
       "333         (1007, 1011)     1007     1011  \n",
       "334         (1008, 1011)     1008     1011  \n",
       "335         (1009, 1011)     1009     1011  \n",
       "336         (1010, 1011)     1010     1011  \n",
       "385         (1009, 1012)     1009     1012  \n",
       "386         (1011, 1012)     1011     1012  \n",
       "472         (1015, 1016)     1015     1016  \n",
       "552           (10, 1022)       10     1022  \n",
       "574         (1009, 1023)     1009     1023  \n",
       "575         (1011, 1023)     1011     1023  \n",
       "576         (1012, 1023)     1012     1023  \n",
       "699         (1000, 1029)     1000     1029  \n",
       "700         (1028, 1029)     1028     1029  \n",
       "750         (1029, 1030)     1029     1030  \n",
       "777         (1029, 1031)     1029     1031  \n",
       "788         (1029, 1032)     1029     1032  \n",
       "796         (1029, 1033)     1029     1033  \n",
       "797         (1030, 1033)     1030     1033  \n",
       "...                  ...      ...      ...  \n",
       "392620  (237695, 237891)   237695   237891  \n",
       "392621  (237718, 237891)   237718   237891  \n",
       "392622  (237720, 237891)   237720   237891  \n",
       "392623  (237722, 237891)   237722   237891  \n",
       "392624  (237734, 237891)   237734   237891  \n",
       "392625  (237737, 237891)   237737   237891  \n",
       "392626  (237741, 237891)   237741   237891  \n",
       "392627  (237742, 237891)   237742   237891  \n",
       "392628  (237745, 237891)   237745   237891  \n",
       "392629  (237750, 237891)   237750   237891  \n",
       "392630  (237751, 237891)   237751   237891  \n",
       "392631  (237754, 237891)   237754   237891  \n",
       "392632  (237763, 237891)   237763   237891  \n",
       "392633  (237772, 237891)   237772   237891  \n",
       "392634  (237781, 237891)   237781   237891  \n",
       "392635  (237802, 237891)   237802   237891  \n",
       "392636  (237807, 237891)   237807   237891  \n",
       "392637  (237811, 237891)   237811   237891  \n",
       "392638  (237817, 237891)   237817   237891  \n",
       "392639  (237822, 237891)   237822   237891  \n",
       "392640  (237828, 237891)   237828   237891  \n",
       "392641  (237830, 237891)   237830   237891  \n",
       "392642  (237840, 237891)   237840   237891  \n",
       "392643  (237859, 237891)   237859   237891  \n",
       "392644  (237862, 237891)   237862   237891  \n",
       "392645  (237867, 237891)   237867   237891  \n",
       "392646  (237876, 237891)   237876   237891  \n",
       "392647  (237886, 237891)   237886   237891  \n",
       "392648  (237888, 237891)   237888   237891  \n",
       "392649  (237890, 237891)   237890   237891  \n",
       "\n",
       "[2146335 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_dfs[(dup_dfs.id_l <> dup_dfs.id_l_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_col_list = ['id_l_new','id_r_new']\n",
    "for n,col in enumerate(new_col_list):\n",
    "    dup_dfs[col] = dup_dfs['id tuples'].apply(lambda location: location[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(sorted_match_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4292665</th>\n",
       "      <td>237867</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292666</th>\n",
       "      <td>237876</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292667</th>\n",
       "      <td>237886</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292668</th>\n",
       "      <td>237888</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292669</th>\n",
       "      <td>237890</td>\n",
       "      <td>237891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       1\n",
       "4292665  237867  237891\n",
       "4292666  237876  237891\n",
       "4292667  237886  237891\n",
       "4292668  237888  237891\n",
       "4292669  237890  237891"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146335, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "      <th>l_org_name</th>\n",
       "      <th>l_city</th>\n",
       "      <th>l_state</th>\n",
       "      <th>l_postal_code</th>\n",
       "      <th>l_web</th>\n",
       "      <th>r_org_name</th>\n",
       "      <th>r_city</th>\n",
       "      <th>r_state</th>\n",
       "      <th>r_postal_code</th>\n",
       "      <th>r_web</th>\n",
       "      <th>jaro_score</th>\n",
       "      <th>fuzz_partial_score</th>\n",
       "      <th>fuzz_sort_score</th>\n",
       "      <th>fuzz_set_score</th>\n",
       "      <th>state_match</th>\n",
       "      <th>zip_match</th>\n",
       "      <th>composite_match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_l, id_r, id_l count, l_org_name, l_city, l_state, l_postal_code, l_web, r_org_name, r_city, r_state, r_postal_code, r_web, jaro_score, fuzz_partial_score, fuzz_sort_score, fuzz_set_score, state_match, zip_match, composite_match_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_conc[full_conc.id_l == '2733']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "      <th>l_org_name</th>\n",
       "      <th>l_city</th>\n",
       "      <th>l_state</th>\n",
       "      <th>l_postal_code</th>\n",
       "      <th>l_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_l, id_r, id_l count, l_org_name, l_city, l_state, l_postal_code, l_web]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_conc[l_conc.id_l=='2734']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248406</th>\n",
       "      <td>2733</td>\n",
       "      <td>2734</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_l  id_r  id_l count\n",
       "248406  2733  2734           9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[(dfs.id_l=='2733') & (dfs.id_r=='2734')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "      <th>l_org_name</th>\n",
       "      <th>l_city</th>\n",
       "      <th>l_state</th>\n",
       "      <th>l_postal_code</th>\n",
       "      <th>l_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_l, id_r, id_l count, l_org_name, l_city, l_state, l_postal_code, l_web]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_conc[(l_conc.id_r=='2733') & (l_conc.id_l=='2734')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>id_r</th>\n",
       "      <th>id_l count</th>\n",
       "      <th>l_org_name</th>\n",
       "      <th>l_city</th>\n",
       "      <th>l_state</th>\n",
       "      <th>l_postal_code</th>\n",
       "      <th>l_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230001</td>\n",
       "      <td>230002</td>\n",
       "      <td>2</td>\n",
       "      <td>LEARN TO READ OF ST JOHNS COUNTY INC</td>\n",
       "      <td>Saint Augustine</td>\n",
       "      <td>fl</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230001</td>\n",
       "      <td>230004</td>\n",
       "      <td>2</td>\n",
       "      <td>LEARN TO READ OF ST JOHNS COUNTY INC</td>\n",
       "      <td>Saint Augustine</td>\n",
       "      <td>fl</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230001</td>\n",
       "      <td>230005</td>\n",
       "      <td>2</td>\n",
       "      <td>LEARN TO READ OF ST JOHNS COUNTY INC</td>\n",
       "      <td>Saint Augustine</td>\n",
       "      <td>fl</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230001</td>\n",
       "      <td>230008</td>\n",
       "      <td>3</td>\n",
       "      <td>LEARN TO READ OF ST JOHNS COUNTY INC</td>\n",
       "      <td>Saint Augustine</td>\n",
       "      <td>fl</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230001</td>\n",
       "      <td>230012</td>\n",
       "      <td>2</td>\n",
       "      <td>LEARN TO READ OF ST JOHNS COUNTY INC</td>\n",
       "      <td>Saint Augustine</td>\n",
       "      <td>fl</td>\n",
       "      <td>#N/A</td>\n",
       "      <td>#N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_l    id_r  id_l count                            l_org_name  \\\n",
       "0  230001  230002           2  LEARN TO READ OF ST JOHNS COUNTY INC   \n",
       "1  230001  230004           2  LEARN TO READ OF ST JOHNS COUNTY INC   \n",
       "2  230001  230005           2  LEARN TO READ OF ST JOHNS COUNTY INC   \n",
       "3  230001  230008           3  LEARN TO READ OF ST JOHNS COUNTY INC   \n",
       "4  230001  230012           2  LEARN TO READ OF ST JOHNS COUNTY INC   \n",
       "\n",
       "            l_city l_state l_postal_code l_web  \n",
       "0  Saint Augustine      fl          #N/A  #N/A  \n",
       "1  Saint Augustine      fl          #N/A  #N/A  \n",
       "2  Saint Augustine      fl          #N/A  #N/A  \n",
       "3  Saint Augustine      fl          #N/A  #N/A  \n",
       "4  Saint Augustine      fl          #N/A  #N/A  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_conc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61678462, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_l</th>\n",
       "      <th>l_org_name</th>\n",
       "      <th>l_city</th>\n",
       "      <th>l_state</th>\n",
       "      <th>l_postal_code</th>\n",
       "      <th>l_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_l, l_org_name, l_city, l_state, l_postal_code, l_web]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_match_data[left_match_data.id_l=='2733']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7891, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define column names\n",
    "org_id = 'Recipient_ID'\n",
    "org_name = 'RecipientName'\n",
    "org_address1 = 'AddressLine1Txt'\n",
    "org_city = 'CityNm'\n",
    "org_state = 'StateAbbreviationCd'\n",
    "org_zip = 'Zip'\n",
    "org_web = 'WebsiteAddressTxt'\n",
    "\n",
    "#set parameters\n",
    "token_match_min = 2 # minimum number of matched tokens to be considered a match\n",
    "token_limiter = .99 # percent of non-single tokens to tokenize, where rare tokens are at the bottom and common at the top\n",
    "name_weight = .75 #note that this is really .75 * 4 because there are 4 org name simularity metrics\n",
    "state_weight = 1\n",
    "zip_weight = 1\n",
    "phone_weight = 1\n",
    "composite_score_min = 3.5 #minimum composite match score to be considered a match\n",
    "\n",
    "start_time = time.time()\n",
    "print \"LOADING INITIAL DATAFRAME...\"\n",
    "\n",
    "df = pd.read_csv('RecipientTableUpdated_1.30.19_utf.csv',keep_default_na=False)\n",
    "\n",
    "df.rename(columns={org_id:'id',org_name:'org_name',org_address1:'address1',org_city:'city',org_state:'state',org_zip:'postal_code',org_web:'web'}, inplace=True)\n",
    "\n",
    "print(\"Dataframe loaded --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"PRE-PROCESSING: NORMALIZE STATES...\"\n",
    "#normalize state codes\n",
    "state_lkup = pd.read_csv('state_lkup.csv',keep_default_na=False)\n",
    "\n",
    "from collections import defaultdict\n",
    "state_dict = defaultdict(list)\n",
    "for state, acronym in zip(state_lkup.state.values,state_lkup.acronym.values):\n",
    "    state_dict[state].append(acronym)\n",
    "\n",
    "df.state = df.state.str.lower()\n",
    "df.state = df.state.replace(state_dict)\n",
    "df.to_csv('org_dup_df.csv')\n",
    "\n",
    "print(\"states normalized --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "chunking_time = time.time()\n",
    "print \"TOKENIZING, IDENTIFYING CANDIDATE MATCH PAIRS...\"\n",
    "\n",
    "n=0\n",
    "dfs_list = []\n",
    "for df in pd.read_csv('org_dup_df.csv',keep_default_na=False,chunksize=10000):\n",
    "    \n",
    "n=n+1\n",
    "start_time = time.time()\n",
    "print n\n",
    "\n",
    "left_df_chunk = df.copy()\n",
    "left_df_chunk.rename(columns={'org_name':'l_org_name','address1':'l_address1','city':'l_city','state':'l_state','postal_code':'l_postal_code','web':'l_web'}, inplace=True)\n",
    "\n",
    "    # for the left dataset\n",
    "left_tokenized_columns = [\n",
    "    'l_org_name',\n",
    "    #'l_acronym',\n",
    "    #'l_alt_name',\n",
    "    #'l_address1',\n",
    "    #'l_address2',\n",
    "    'l_city', \n",
    "    'l_state', \n",
    "    'l_postal_code',\n",
    "    'l_web' \n",
    "    #'l_phone'\n",
    "]\n",
    "\n",
    "# lowercase the name and split on spaces, remove non-alphanumeric chars\n",
    "def tokenize_name(name):\n",
    "    if isinstance(name, basestring) is True:\n",
    "        clean_name = ''.join(c if c.isalnum() else ' ' for c in name)\n",
    "        return clean_name.lower().split()\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "unique_tokens = [] #we treat state and zips differently because we want to include ALl state and zip tokens as these are unique\n",
    "\n",
    "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< add chosen unique columns here from each df\n",
    "for word in left_df_chunk['l_state']:\n",
    "    if isinstance(word, float) is False:\n",
    "        unique_tokens.append(tokenize_name(str(word)))\n",
    "\n",
    "for word in left_df_chunk['l_postal_code']:\n",
    "    if isinstance(word, float) is False:\n",
    "        unique_tokens.append(tokenize_name(str(word)))\n",
    "\n",
    "#for word in left_df_chunk['l_acronym']:\n",
    "#    if isinstance(word, float) is False:\n",
    "#        unique_tokens.append(tokenize_name(str(word)))\n",
    "\n",
    "#for word in left_df_chunk['l_phone']:\n",
    "#    if isinstance(word, float) is False:\n",
    "#        unique_tokens.append(tokenize_name(str(word)))\n",
    "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "unique_flat_list = [item for sublist in unique_tokens for item in sublist]\n",
    "\n",
    "#instantiate counter and use to count word frequencies in flat list\n",
    "u_cnt = Counter()\n",
    "for token in unique_flat_list:\n",
    "    u_cnt[token] += 1\n",
    "\n",
    "u_cnt_dict = dict(u_cnt) #convert to dictionary\n",
    "\n",
    "unique_tokens_df = pd.DataFrame(u_cnt_dict.items(), columns=['token', 'count'])\n",
    "unique_tokens_df = unique_tokens_df.sort_values(by='count')  #sorting by count so that we can take the first x% of tokens by rare frequency\n",
    "\n",
    "unique_token_flag = []\n",
    "for index, value in enumerate(unique_tokens_df['count']):\n",
    "    if value == 1:\n",
    "        unique_token_flag.append(0)  #for any tokens occuring only once, we exclude\n",
    "    else:\n",
    "        unique_token_flag.append(1)\n",
    "\n",
    "unique_tokens_df['flag'] = unique_token_flag        \n",
    "\n",
    "all_other_words = [] #creating a list of all words used in just ONE of the dfs in selected columns, for counting to determine rarity\n",
    "\n",
    "for word in left_df_chunk['l_org_name']:\n",
    "    if isinstance(word, float) is False:\n",
    "        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "#for word in left_df_chunk['l_alt_name']:\n",
    "#    if isinstance(word, float) is False:\n",
    "#        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "#for word in left_df_chunk['l_address1']:\n",
    "#    if isinstance(word, float) is False:\n",
    "#        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "for word in left_df_chunk['l_city']:\n",
    "    if isinstance(word, float) is False:\n",
    "        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "for word in left_df_chunk['l_web']:\n",
    "    if isinstance(word, float) is False:\n",
    "        all_other_words.append(tokenize_name(str(word)))\n",
    "\n",
    "flat_list = [item for sublist in all_other_words for item in sublist] #flatten list so it can be counted\n",
    "\n",
    "#instantiate counter and use to count word frequencies in flat list\n",
    "cnt = Counter()\n",
    "for token in flat_list:\n",
    "    cnt[token] += 1\n",
    "\n",
    "cnt_dict = dict(cnt) #convert to dictionary\n",
    "\n",
    "main_tokens_df = pd.DataFrame(cnt_dict.items(), columns=['token', 'count'])\n",
    "main_tokens_df = main_tokens_df.sort_values(by='count')  #sorting by count so that we can take the first x% of tokens by rare frequency\n",
    "\n",
    "main_token_flag = []\n",
    "for index, value in enumerate(main_tokens_df['count']):\n",
    "    if value == 1:\n",
    "        main_token_flag.append(0)  #for any tokens occuring only once, we exclude\n",
    "    elif index < int(main_tokens_df.shape[0] * token_limiter): #important line, we are cutting the top x% of frequently occuring tokens\n",
    "        main_token_flag.append(1)\n",
    "    else:\n",
    "        main_token_flag.append(0)  #for the most common tokens, we exclude\n",
    "\n",
    "main_tokens_df['flag'] = main_token_flag\n",
    "\n",
    "all_tokens = pd.concat([unique_tokens_df, main_tokens_df])\n",
    "\n",
    "all_tokens.drop('count',axis=1,inplace=True)\n",
    "all_tokens['flag'] = all_tokens.flag.astype(int) #converting flags to int\n",
    "tokens_dct = all_tokens.to_dict('split') #converting tokens_df to dictionary\n",
    "tokens_dct=dict(tokens_dct['data']) #honestly can't remember why this works, something to do with conversion to dictionary\n",
    "\n",
    "#preparing token_ids which will be used for joining left and right dfs\n",
    "all_tokens.sort_values(by='flag',ascending=False,inplace=True)\n",
    "all_tokens.drop_duplicates(subset='token',keep='first',inplace=True)\n",
    "token_ids = all_tokens.index.get_level_values(0)\n",
    "all_tokens['token_id'] = token_ids\n",
    "\n",
    "all_tokens.drop('flag',axis=1,inplace=True)\n",
    "all_tokens['token_id'] = all_tokens.token_id.astype(int)\n",
    "token_id_dct = all_tokens.to_dict('split')\n",
    "tokens_id_dct=dict(token_id_dct['data'])\n",
    "\n",
    "vocabulary = np.array([w for w, c in tokens_dct.items() if c ==1]) #this works even without the ==1 and I don't know why\n",
    "cv = CountVectorizer( vocabulary=vocabulary)\n",
    "\n",
    "frame_list = []\n",
    "for colname in left_tokenized_columns:\n",
    "    tokenmapping = cv.fit_transform(left_df_chunk[colname])\n",
    "    df_row, token_id = tokenmapping.nonzero()\n",
    "\n",
    "    frame_list.append(pd.DataFrame(np.vstack([vocabulary[token_id], left_df_chunk['id'].values[df_row]]).T, columns = ['token', 'id']))\n",
    "\n",
    "left_keyed = pd.concat(frame_list)\n",
    "\n",
    "#append token_id to token as this will be more efficient to join with\n",
    "left_token_ids = []\n",
    "for token in left_keyed.token:\n",
    "    left_token_ids.append(tokens_id_dct[token])\n",
    "\n",
    "left_keyed['token_id'] = left_token_ids\n",
    "left_keyed.sort_values(by='token_id',inplace=True)\n",
    "left_keyed.set_index('token_id',inplace=True)\n",
    "left_keyed.drop('token',axis=1,inplace=True)\n",
    "\n",
    "aggregations = {\n",
    "    'id_l': 'count'\n",
    "}\n",
    "\n",
    "right_keyed = left_keyed.copy()\n",
    "joined = left_keyed.join(right_keyed, how='inner',lsuffix='_l',rsuffix='_r')\n",
    "keys_grouped = joined.groupby(by=['id_l', 'id_r']).agg(aggregations)\n",
    "keys_grouped.rename(columns={'id_l':'id_l count'}, inplace=True)\n",
    "matched_records = keys_grouped[keys_grouped['id_l count'] >= token_match_min]\n",
    "matched_records.reset_index(inplace=True)\n",
    "duplicate_candidates = matched_records[matched_records['id_l'] <> matched_records['id_r']]\n",
    "\n",
    "#add chunk duplicate candidates to df list\n",
    "dfs_list.append(duplicate_candidates)\n",
    "\n",
    "print(\"chunk loaded --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "dup_dfs = pd.concat(dfs_list)\n",
    "print(\"All chunks loaded --- %s seconds ---\" % (time.time() - chunking_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"REMOVING REDUNDANT DUPLICATE ID PAIRS...\"\n",
    "\n",
    "match_tuples = list(zip(dup_dfs['id_l'], dup_dfs['id_r']))\n",
    "\n",
    "sorted_match_tuples = []\n",
    "for tup in match_tuples:\n",
    "    s = tuple(sorted(tup))\n",
    "    sorted_match_tuples.append(s)\n",
    "\n",
    "dup_dfs.drop(['id_l','id_r'],axis=1,inplace=True)\n",
    "dup_dfs['id_tuples'] = sorted_match_tuples\n",
    "\n",
    "new_col_list = ['id_l','id_r']\n",
    "for n,col in enumerate(new_col_list):\n",
    "    dup_dfs[col] = dup_dfs['id_tuples'].apply(lambda location: location[n])\n",
    "    \n",
    "dup_dfs.drop('id_tuples',axis=1,inplace=True)\n",
    "dup_dfs.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"redundant id pairs removed --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"APPENDING ORIGINAL DATA TO MATCH CANDIDATES...\"\n",
    "\n",
    "left_df = pd.read_csv('org_dup_df.csv')\n",
    "right_df = left_df.copy()\n",
    "left_df.rename(columns={'id':'id_l','org_name':'l_org_name','address1':'l_address1','city':'l_city','state':'l_state','postal_code':'l_postal_code','web':'l_web'}, inplace=True)\n",
    "right_df.rename(columns={'id':'id_r','org_name':'r_org_name','address1':'r_address1','city':'r_city','state':'r_state','postal_code':'r_postal_code','web':'r_web'}, inplace=True)\n",
    "\n",
    "#creating left/right dataframes which contain only the most relevant details for reviewing the match strengths\n",
    "left_match_data = left_df[['id_l','l_org_name','l_city','l_state','l_postal_code','l_web']].copy()\n",
    "right_match_data = right_df[['id_r','r_org_name','r_city','r_state','r_postal_code','r_web']].copy()\n",
    "\n",
    "#making sure keys are str, results in blank df otherwise\n",
    "left_match_data.id_l = left_match_data.id_l.astype('str')\n",
    "right_match_data.id_r = right_match_data.id_r.astype('str')\n",
    "dup_dfs.id_l = dup_dfs.id_l.astype('str')\n",
    "dup_dfs.id_r = dup_dfs.id_r.astype('str')\n",
    "\n",
    "#merging matched_records df with original record data for ease of review\n",
    "l_conc = pd.merge(dup_dfs, left_match_data, on='id_l')\n",
    "full_conc = pd.merge(l_conc, right_match_data, on='id_r')\n",
    "\n",
    "print(\"original data concatenated with matches --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"SCORING ORG NAME SIMULARITY...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#scoring match candidates based on edit distance of org names\n",
    "def jaro_simularity(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return jaro_winkler(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '')\n",
    "def fuzz_partial(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return fuzz.partial_ratio(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '') / float(100)\n",
    "def fuzz_sort(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return fuzz.token_sort_ratio(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '') / float(100)\n",
    "def fuzz_set(left_record, right_record):\n",
    "    if isinstance(left_record, numbers.Integral) is False and isinstance(right_record, numbers.Integral) is False:\n",
    "        return fuzz.token_set_ratio(unicode(left_record, 'utf-8') or '', unicode(right_record, 'utf-8') or '') / float(100)\n",
    "\n",
    "full_conc['l_org_name'] = full_conc['l_org_name'].astype('str')\n",
    "full_conc['r_org_name'] = full_conc['r_org_name'].astype('str')\n",
    "\n",
    "jaro_time = time.time()\n",
    "full_conc['jaro_score'] = full_conc.apply(lambda x: jaro_simularity(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"jaro scores done --- %s seconds ---\" % (time.time() - jaro_time))\n",
    "partial_time = time.time()\n",
    "full_conc['fuzz_partial_score'] = full_conc.apply(lambda x: fuzz_partial(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"fuzz partial scores done --- %s seconds ---\" % (time.time() - partial_time))\n",
    "sort_time = time.time()\n",
    "full_conc['fuzz_sort_score'] = full_conc.apply(lambda x: fuzz_sort(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"fuzz sort scores done --- %s seconds ---\" % (time.time() - sort_time))\n",
    "set_time = time.time()\n",
    "full_conc['fuzz_set_score'] = full_conc.apply(lambda x: fuzz_set(x.l_org_name, x.r_org_name), axis=1)\n",
    "print(\"fuzz set scores done --- %s seconds ---\" % (time.time() - set_time))\n",
    "print \"\"\n",
    "\n",
    "print(\"name simularity scored --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"CHECKING FOR STATE CODE MATCHES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "def sanitize_state(state):\n",
    "    if isinstance(state,basestring) is True:\n",
    "        return ''.join(c for c in (state or '') if c in 'abcdefghijklmnopqrstuvwxyz')\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def state_match(state_a, state_b):\n",
    "    sanitized_state_a = str(sanitize_state(state_a))\n",
    "    sanitized_state_b = str(sanitize_state(state_b))\n",
    "\n",
    "    # if the value is too short, means it's fubar\n",
    "    if len(sanitized_state_a) < 2 or len(sanitized_state_b) < 2:\n",
    "        return 0\n",
    "    if state_a == state_b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "full_conc['state_match'] = full_conc.apply(lambda x: state_match(x.l_state, x.r_state), axis=1)\n",
    "\n",
    "print(\"state codes checked --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "start_time = time.time()\n",
    "print \"CHECKING FOR POSTAL CODE MATCHES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#scoring match candidates based on matching postal code\n",
    "\n",
    "def sanitize_postal(postal):\n",
    "    if isinstance(postal, basestring) is True:\n",
    "        return ''.join(c for c in (postal or '') if c in '1234567890')\n",
    "    if isinstance(postal, float) is False:\n",
    "        return postal\n",
    "\n",
    "def postal_simularity(postal_a, postal_b):\n",
    "    sanitized_postal_a = str(sanitize_postal(postal_a))\n",
    "    sanitized_postal_b = str(sanitize_postal(postal_b))\n",
    "\n",
    "    # if the number is too short, means it's fubar\n",
    "    if len(sanitized_postal_a) < 5 or len(sanitized_postal_b) < 5:\n",
    "        return 0\n",
    "    if float(max(len(sub) for sub in find_common_subsequences(sanitized_postal_a, sanitized_postal_b))) / 5 >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "full_conc['zip_match'] = full_conc.apply(lambda x: postal_simularity(x.l_postal_code, x.r_postal_code), axis=1)\n",
    "    \n",
    "print(\"postal codes checked --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "#start_time = time.time()\n",
    "#print \"CHECKING FOR PHONE MATCHES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#scoring match candidates based on matching postal code\n",
    "\n",
    "#def sanitize_phone(phone):\n",
    "#    if isinstance(phone, basestring) is True:\n",
    "#        return ''.join(c for c in (phone or '') if c in '1234567890')\n",
    "#    if isinstance(phone, float) is False:\n",
    "#        return phone\n",
    "\n",
    "#def postal_simularity(phone_a, phone_b):\n",
    "#    sanitized_phone_a = str(sanitize_phone(phone_a))\n",
    "#    sanitized_phone_b = str(sanitize_phone(phone_b))\n",
    "\n",
    "    # if the number is too short, means it's fubar\n",
    "#    if len(sanitized_phone_a) < 10 or len(sanitized_phone_b) < 10:\n",
    "#        return 0\n",
    "#    if float(max(len(sub) for sub in find_common_subsequences(sanitized_phone_a, sanitized_phone_b))) / 10 >= 1:\n",
    "#        return 1\n",
    "#    else:\n",
    "#        return 0\n",
    "    \n",
    "#full_conc['phone_match'] = full_conc.apply(lambda x: phone_simularity(x.l_phone, x.r_phone), axis=1)\n",
    "    \n",
    "#print(\"phones checked --- %s seconds ---\" % (time.time() - start_time))\n",
    "#print \"\"\n",
    "\n",
    "#test this.  may need to make more efficient but I think it should work\n",
    "start_time = time.time()\n",
    "print \"DISTILLING STRONG ORG DUPLICATES...\" #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "#calculate composite match score based on component scores and weights\n",
    "full_conc['composite_match_score'] = full_conc.jaro_score * name_weight \\\n",
    "+ full_conc.fuzz_partial_score * name_weight \\\n",
    "+ full_conc.fuzz_sort_score * name_weight \\\n",
    "+ full_conc.fuzz_set_score * name_weight \\\n",
    "+ full_conc.zip_match * zip_weight \\\n",
    "+ full_conc.state_match * state_weight \\\n",
    "#+ full_conc.phone_match * phone_weight\n",
    "\n",
    "org_duplicates = full_conc[full_conc.composite_match_score >= composite_score_min]\n",
    "\n",
    "print(\"final duplicates isolated --- %s seconds ---\" % (time.time() - start_time))\n",
    "print \"\"\n",
    "\n",
    "#full_conc[full_conc.composite_match_score < 3].sort_values(by='composite_match_score', ascending=False)\n",
    "org_duplicates.sort_values(by='composite_match_score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
